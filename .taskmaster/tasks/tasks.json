{
  "project": "news-cartoon",
  "version": "1.0.0",
  "description": "Regression Test Suite for News Cartoon Application",
  "tags": {
    "master": {
      "name": "master",
      "description": "Default tag",
      "createdAt": "2025-11-09T00:00:00.000Z",
      "tasks": []
    },
    "regression-tests": {
      "name": "regression-tests",
      "description": "Comprehensive regression test suite for news-cartoon application",
      "createdAt": "2025-11-09T00:00:00.000Z",
      "tasks": [
        {
          "id": "1",
          "title": "Set up comprehensive test infrastructure",
          "description": "Configure Vitest, React Testing Library, and test utilities for the project",
          "details": "- Configure Vitest in vite.config.ts with jsdom environment\n- Set up comprehensive test globals and mocks in src/test/setup.ts\n- Create shared test utilities and custom render functions\n- Configure code coverage with 80% threshold targets\n- Set up test data fixtures and factory functions\n- Add MSW (Mock Service Worker) for API mocking\n- Configure pre-commit hooks for test running",
          "testStrategy": "Run npm test to verify all configurations work. Generate coverage report and ensure it displays correctly.",
          "priority": "high",
          "status": "pending",
          "dependencies": [],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "2",
          "title": "Create unit tests for all service modules",
          "description": "Write comprehensive unit tests for newsService, geminiService, and locationService",
          "details": "- Test newsService: fetchNewsByLocation, fetchNewsByKeyword, caching, retry logic\n- Test geminiService: generateCartoonConcepts, generateComicScript, generateCartoonImage, caching\n- Test locationService: detectLocation, getLocationFromGPS, getLocationFromIP\n- Mock all external API calls and browser APIs\n- Test error handling, edge cases, and retry mechanisms\n- Achieve 90%+ coverage for service layer",
          "testStrategy": "Each service should have its own test file. Verify all public methods are tested with various scenarios.",
          "priority": "high",
          "status": "pending",
          "dependencies": [
            "1"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "3",
          "title": "Create unit tests for all Zustand stores",
          "description": "Write comprehensive tests for cartoonStore, newsStore, locationStore, and preferencesStore",
          "details": "- Test all store actions and state transitions\n- Test localStorage persistence and hydration\n- Test store reset functionality\n- Test computed values and selectors\n- Test error state management\n- Verify store isolation and independence",
          "testStrategy": "Create separate test files for each store. Use renderHook from React Testing Library to test store hooks.",
          "priority": "high",
          "status": "pending",
          "dependencies": [
            "1"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "4",
          "title": "Create component tests for all React components",
          "description": "Write comprehensive component tests using React Testing Library",
          "details": "- Test NewsDisplay component with various article states\n- Test ConceptGenerator with concept selection flow\n- Test ImageGenerator with rate limiting scenarios\n- Test LocationDetector with GPS and manual entry\n- Test Layout, ErrorBoundary, and navigation components\n- Test loading states, error states, and user interactions\n- Verify accessibility and ARIA attributes",
          "testStrategy": "Each component should have a corresponding .test.tsx file. Use userEvent for interactions.",
          "priority": "high",
          "status": "pending",
          "dependencies": [
            "1"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "5",
          "title": "Set up Playwright for E2E testing",
          "description": "Configure Playwright and create end-to-end tests for critical user journeys",
          "details": "- Install and configure Playwright with multiple browsers\n- Create E2E tests for location-based news flow\n- Test keyword search and article display\n- Test complete cartoon generation flow\n- Test rate limiting and error recovery\n- Test settings persistence across sessions\n- Set up visual regression testing\n- Configure parallel test execution",
          "testStrategy": "Run playwright test to verify all user flows work correctly across browsers.",
          "priority": "medium",
          "status": "pending",
          "dependencies": [
            "2",
            "3",
            "4"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "6",
          "title": "Create API and backend tests",
          "description": "Write comprehensive tests for the Express backend server",
          "details": "- Test /api/news/search endpoint with various queries\n- Test /api/article/content scraping functionality\n- Test RSS feed parsing from Google News\n- Test error handling and status codes\n- Test CORS configuration\n- Test request validation and sanitization\n- Test caching mechanisms\n- Use supertest for API testing",
          "testStrategy": "Run server tests separately with npm run test:server. Verify all endpoints handle edge cases.",
          "priority": "medium",
          "status": "pending",
          "dependencies": [
            "1"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "7",
          "title": "Set up CI/CD test automation",
          "description": "Configure GitHub Actions or similar CI/CD for automated testing",
          "details": "- Create workflow for running tests on pull requests\n- Set up test matrix for multiple Node versions\n- Configure code coverage reporting to Codecov or similar\n- Set up branch protection requiring passing tests\n- Configure performance budget checks\n- Add bundle size analysis\n- Set up automated dependency updates with tests",
          "testStrategy": "Push changes to trigger CI/CD pipeline. Verify all checks pass and reports generate.",
          "priority": "medium",
          "status": "pending",
          "dependencies": [
            "5",
            "6"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        },
        {
          "id": "8",
          "title": "Create testing documentation and guidelines",
          "description": "Document testing strategies, patterns, and best practices for the project",
          "details": "- Write comprehensive testing guide in docs/TESTING.md\n- Document test running commands and options\n- Create troubleshooting guide for common test issues\n- Document mocking strategies and patterns\n- Create examples of good test practices\n- Document coverage goals and how to improve them\n- Create contribution guidelines for test requirements",
          "testStrategy": "Review documentation with team. Ensure new contributors can understand and run tests.",
          "priority": "low",
          "status": "pending",
          "dependencies": [
            "7"
          ],
          "createdAt": "2025-11-09T00:00:00.000Z",
          "subtasks": []
        }
      ]
    }
  },
  "metadata": {
    "createdAt": "2025-11-09T00:00:00.000Z",
    "updatedAt": "2025-11-09T00:00:00.000Z",
    "currentTag": "regression-tests"
  },
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Set up Testing Infrastructure and Configuration",
        "description": "Configure the testing environment with Vitest, React Testing Library, Playwright, and MSW. Set up the CI/CD pipeline integration for automated test runs.",
        "details": "1. Install required dependencies:\n```bash\nnpm install --save-dev vitest @testing-library/react @testing-library/user-event @testing-library/jest-dom msw playwright\n```\n\n2. Configure Vitest for unit and integration tests:\n```javascript\n// vitest.config.js\nimport { defineConfig } from 'vitest/config'\nimport react from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [react()],\n  test: {\n    environment: 'jsdom',\n    globals: true,\n    setupFiles: './src/test/setup.js',\n    coverage: {\n      reporter: ['text', 'json', 'html'],\n      statements: 80,\n      branches: 75,\n      functions: 80,\n      lines: 80\n    },\n  },\n})\n```\n\n3. Create test setup file:\n```javascript\n// src/test/setup.js\nimport '@testing-library/jest-dom'\nimport { server } from './mocks/server'\n\nbeforeAll(() => server.listen())\nafterEach(() => server.resetHandlers())\nafterAll(() => server.close())\n```\n\n4. Configure MSW for API mocking:\n```javascript\n// src/test/mocks/server.js\nimport { setupServer } from 'msw/node'\nimport { handlers } from './handlers'\n\nexport const server = setupServer(...handlers)\n```\n\n5. Set up Playwright for E2E testing:\n```bash\nnpx playwright install\n```\n\n6. Create Playwright configuration:\n```javascript\n// playwright.config.js\nexport default {\n  testDir: './e2e',\n  timeout: 30000,\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n  },\n  projects: [\n    { name: 'chromium', use: { browserName: 'chromium' } },\n    { name: 'firefox', use: { browserName: 'firefox' } },\n    { name: 'webkit', use: { browserName: 'webkit' } },\n    { name: 'mobile', use: { browserName: 'chromium', viewport: { width: 390, height: 844 } } }\n  ],\n}\n```\n\n7. Configure CI/CD pipeline (GitHub Actions example):\n```yaml\n# .github/workflows/test.yml\nname: Test Suite\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - run: npm ci\n      - run: npm run test:unit\n      - run: npm run test:e2e\n      - name: Upload coverage reports\n        uses: codecov/codecov-action@v3\n```\n\n8. Add scripts to package.json:\n```json\n{\n  \"scripts\": {\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\",\n    \"test:coverage\": \"vitest run --coverage\",\n    \"test:e2e\": \"playwright test\",\n    \"test:ci\": \"npm run test && npm run test:e2e\"\n  }\n}\n```\n\n9. Set up pre-commit hooks with Husky:\n```bash\nnpm install --save-dev husky lint-staged\nnpx husky install\nnpx husky add .husky/pre-commit \"npx lint-staged\"\n```\n\n10. Configure lint-staged in package.json:\n```json\n{\n  \"lint-staged\": {\n    \"*.{js,jsx,ts,tsx}\": [\"eslint --fix\", \"vitest related --run\"]\n  }\n}\n```",
        "testStrategy": "1. Verify that all testing tools are correctly installed and configured by running sample tests for each type (unit, component, integration, E2E).\n2. Validate CI/CD pipeline configuration by pushing a test commit and confirming that tests run automatically.\n3. Check that coverage reporting is working by running the coverage command and verifying the output report.\n4. Test pre-commit hooks by making changes and attempting to commit them.\n5. Verify that the testing environment correctly mocks external dependencies by writing a simple test that uses MSW to intercept API calls.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Install and Configure Testing Libraries",
            "description": "Install all required testing dependencies and create basic configuration files for Vitest, React Testing Library, and MSW.",
            "dependencies": [],
            "details": "Run npm install to add all testing dependencies. Create the vitest.config.js file with proper configuration for React components testing. Set up the test setup file that includes jest-dom extensions and MSW server initialization. Create the initial MSW server configuration file structure.",
            "status": "done",
            "testStrategy": "Verify successful installation by running a simple test command and checking that the environment is properly configured."
          },
          {
            "id": 2,
            "title": "Set Up Mock Service Worker for API Mocking",
            "description": "Configure MSW handlers and server for mocking API responses in tests.",
            "dependencies": [],
            "details": "Create the handlers.js file with mock implementations for all API endpoints used in the application. Set up the MSW server configuration to use these handlers. Implement request handlers for news API, Gemini API, and location services. Create sample response fixtures that match the expected API response structure.",
            "status": "done",
            "testStrategy": "Create a simple test that uses MSW to verify API mocking is working correctly."
          },
          {
            "id": 3,
            "title": "Configure Playwright for E2E Testing",
            "description": "Set up Playwright for end-to-end testing with multi-browser and mobile viewport support.",
            "dependencies": [],
            "details": "Install Playwright browsers using npx playwright install. Create the playwright.config.js file with configuration for multiple browsers (Chrome, Firefox, Safari) and mobile viewport. Set up test fixtures and helper functions for common E2E testing patterns. Configure screenshot and trace capturing for test failures.",
            "status": "done",
            "testStrategy": "Run a simple Playwright test against a static page to verify the E2E setup is working correctly across browsers."
          },
          {
            "id": 4,
            "title": "Set Up CI/CD Pipeline Integration",
            "description": "Configure GitHub Actions workflow for automated test execution on push and pull requests.",
            "dependencies": [],
            "details": "Create the GitHub Actions workflow file (.github/workflows/test.yml) that runs unit, integration, and E2E tests. Configure the workflow to upload test coverage reports to Codecov. Set up caching for node_modules to improve CI performance. Configure the workflow to run tests in parallel where possible.",
            "status": "done",
            "testStrategy": "Push a test commit to verify that the GitHub Actions workflow runs successfully and reports test results correctly."
          },
          {
            "id": 5,
            "title": "Implement Pre-commit Hooks and Documentation",
            "description": "Set up Husky and lint-staged for pre-commit test validation, and document the testing infrastructure.",
            "dependencies": [],
            "details": "Install and configure Husky for git hooks. Set up lint-staged to run relevant tests on staged files before commit. Add test scripts to package.json for different test types (unit, e2e, coverage). Create a TESTING.md file documenting the testing strategy, tools, and patterns used in the project. Include examples of how to write tests for components, services, and stores.",
            "status": "done",
            "testStrategy": "Make a test commit with both passing and failing tests to verify that pre-commit hooks correctly prevent commits with failing tests."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Unit Tests for Services and Stores",
        "description": "Create comprehensive unit tests for all service modules (newsService, geminiService, locationService) and Zustand stores (cartoonStore, newsStore, locationStore, preferencesStore) with proper mocking of external dependencies.",
        "details": "1. Create test files for each service:\n```javascript\n// src/services/__tests__/newsService.test.js\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\nimport { fetchNews, parseArticle } from '../newsService'\nimport { rest } from 'msw'\nimport { server } from '../../test/mocks/server'\n\ndescribe('newsService', () => {\n  beforeEach(() => {\n    vi.resetAllMocks()\n  })\n\n  it('fetches news successfully', async () => {\n    // Mock successful API response\n    server.use(\n      rest.get('/api/news/search', (req, res, ctx) => {\n        return res(ctx.json({ articles: [{ id: 1, title: 'Test Article' }] }))\n      })\n    )\n\n    const result = await fetchNews('test location')\n    expect(result.articles).toHaveLength(1)\n    expect(result.articles[0].title).toBe('Test Article')\n  })\n\n  it('handles API errors gracefully', async () => {\n    // Mock API error\n    server.use(\n      rest.get('/api/news/search', (req, res, ctx) => {\n        return res(ctx.status(500))\n      })\n    )\n\n    await expect(fetchNews('test location')).rejects.toThrow()\n  })\n\n  // Additional tests for other functions\n})\n```\n\n2. Create similar test files for geminiService and locationService.\n\n3. Test Zustand stores:\n```javascript\n// src/stores/__tests__/cartoonStore.test.js\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\nimport { createCartoonStore } from '../cartoonStore'\nimport { act, renderHook } from '@testing-library/react'\nimport * as geminiService from '../../services/geminiService'\n\n// Mock the geminiService\nvi.mock('../../services/geminiService', () => ({\n  generateCartoonConcept: vi.fn(),\n  generateImage: vi.fn()\n}))\n\ndescribe('cartoonStore', () => {\n  beforeEach(() => {\n    vi.resetAllMocks()\n  })\n\n  it('initializes with default state', () => {\n    const { result } = renderHook(() => createCartoonStore())\n    \n    expect(result.current.cartoon).toBeNull()\n    expect(result.current.isLoading).toBe(false)\n    expect(result.current.error).toBeNull()\n  })\n\n  it('generates cartoon concept successfully', async () => {\n    // Mock successful concept generation\n    geminiService.generateCartoonConcept.mockResolvedValue('Funny concept')\n    \n    const { result } = renderHook(() => createCartoonStore())\n    \n    await act(async () => {\n      await result.current.generateConcept('Test article')\n    })\n    \n    expect(geminiService.generateCartoonConcept).toHaveBeenCalledWith('Test article')\n    expect(result.current.concept).toBe('Funny concept')\n    expect(result.current.isLoading).toBe(false)\n  })\n\n  it('handles errors during concept generation', async () => {\n    // Mock error\n    geminiService.generateCartoonConcept.mockRejectedValue(new Error('API error'))\n    \n    const { result } = renderHook(() => createCartoonStore())\n    \n    await act(async () => {\n      await result.current.generateConcept('Test article')\n    })\n    \n    expect(result.current.error).toBeTruthy()\n    expect(result.current.isLoading).toBe(false)\n  })\n\n  // Additional tests for other actions\n})\n```\n\n4. Create similar test files for newsStore, locationStore, and preferencesStore.\n\n5. Test utility functions:\n```javascript\n// src/utils/__tests__/errorHandler.test.js\nimport { describe, it, expect, vi } from 'vitest'\nimport { handleApiError, logError } from '../errorHandler'\n\ndescribe('errorHandler', () => {\n  it('formats API errors correctly', () => {\n    const error = new Error('Network error')\n    error.response = { status: 404, data: { message: 'Not found' } }\n    \n    const result = handleApiError(error)\n    \n    expect(result).toEqual({\n      message: 'Not found',\n      status: 404,\n      isApiError: true\n    })\n  })\n\n  it('handles non-API errors', () => {\n    const error = new Error('Generic error')\n    \n    const result = handleApiError(error)\n    \n    expect(result).toEqual({\n      message: 'Generic error',\n      status: 500,\n      isApiError: false\n    })\n  })\n\n  // Additional tests\n})\n```\n\n6. Create similar test files for rateLimiter and cache utilities.\n\n7. Test edge cases and error handling for all services and stores:\n   - Empty responses\n   - Malformed data\n   - Network timeouts\n   - Rate limiting scenarios\n   - Cache hits and misses",
        "testStrategy": "1. Use Vitest's mocking capabilities to isolate units under test from external dependencies.\n2. Test both success and failure paths for all functions.\n3. Verify that stores correctly manage state transitions (loading, success, error states).\n4. Use MSW to mock API responses for service tests.\n5. Test edge cases such as empty data, malformed responses, and error conditions.\n6. Validate that error handling works as expected across all modules.\n7. Ensure rate limiting and caching utilities function correctly under various scenarios.\n8. Run tests in isolation and verify they don't have side effects on other tests.\n9. Aim for 80%+ code coverage for all tested modules.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Unit Tests for News Service",
            "description": "Create comprehensive unit tests for the newsService module, covering all functions including fetchNews and parseArticle. Test both success and error scenarios with proper mocking of external dependencies.",
            "dependencies": [],
            "details": "Create test file at src/services/__tests__/newsService.test.js. Use MSW to mock API responses. Test successful API calls, error handling, edge cases like empty responses, and utility functions. Ensure all exported functions are covered with tests for different input scenarios. Mock the fetch API and test rate limiting behavior.",
            "status": "pending",
            "testStrategy": "Use MSW to intercept and mock API calls. Test both success and error paths. Verify correct parsing of different response formats. Test edge cases like malformed data and network timeouts."
          },
          {
            "id": 2,
            "title": "Implement Unit Tests for Gemini and Location Services",
            "description": "Create unit tests for geminiService (AI generation) and locationService modules, ensuring all functions are tested with proper mocking of external dependencies.",
            "dependencies": [],
            "details": "Create test files at src/services/__tests__/geminiService.test.js and src/services/__tests__/locationService.test.js. Mock API responses for both services. For geminiService, test image generation, concept creation, and error handling. For locationService, test geolocation fetching, address parsing, and caching mechanisms. Ensure proper error handling tests for API failures.",
            "status": "pending",
            "testStrategy": "Mock external API calls using MSW or vi.mock. Test rate limiting, caching behavior, and error recovery strategies. Verify that services handle malformed responses gracefully."
          },
          {
            "id": 3,
            "title": "Implement Unit Tests for Cartoon and News Stores",
            "description": "Create unit tests for the Zustand stores cartoonStore and newsStore, verifying state management, actions, and integration with their respective services.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Create test files at src/stores/__tests__/cartoonStore.test.js and src/stores/__tests__/newsStore.test.js. Use renderHook from @testing-library/react to test store hooks. Mock the geminiService and newsService dependencies. Test initial state, state transitions during loading/success/error, and all store actions. Verify that stores correctly handle service responses and errors.",
            "status": "pending",
            "testStrategy": "Mock service dependencies using vi.mock. Test state transitions through all possible flows. Verify that loading states, error handling, and success scenarios work correctly. Test store selectors and derived state."
          },
          {
            "id": 4,
            "title": "Implement Unit Tests for Location and Preferences Stores",
            "description": "Create unit tests for the locationStore and preferencesStore Zustand stores, verifying state management, persistence, and integration with services.",
            "dependencies": [
              "2.2"
            ],
            "details": "Create test files at src/stores/__tests__/locationStore.test.js and src/stores/__tests__/preferencesStore.test.js. Test initial state loading, state persistence to localStorage, and all store actions. For locationStore, mock the locationService and test location fetching, caching, and error handling. For preferencesStore, test theme switching, preference saving, and default values.",
            "status": "pending",
            "testStrategy": "Mock localStorage access to test persistence. Test that stores correctly load initial state from storage. Verify that all actions correctly update state and trigger side effects like storage updates."
          },
          {
            "id": 5,
            "title": "Implement Unit Tests for Utility Functions",
            "description": "Create unit tests for all utility functions including error handlers, rate limiters, and caching utilities, ensuring they work correctly in isolation.",
            "dependencies": [],
            "details": "Create test files for each utility module (e.g., src/utils/__tests__/errorHandler.test.js, src/utils/__tests__/rateLimiter.test.js, src/utils/__tests__/cache.test.js). Test error formatting, logging, rate limiting behavior with different configurations, and cache hit/miss scenarios. Verify that utilities handle edge cases correctly.",
            "status": "pending",
            "testStrategy": "Test utilities in isolation with various input scenarios. For time-based utilities like rate limiters, use vi.useFakeTimers() to control time. Test cache expiration, eviction policies, and storage limits."
          }
        ]
      },
      {
        "id": 3,
        "title": "Develop Component and Integration Tests",
        "description": "Create tests for all React components in isolation and test their integration with stores and services. Validate component props, state, interactions, accessibility, and responsive behavior.",
        "details": "1. Create component tests for UI elements:\n```javascript\n// src/components/__tests__/NewsCard.test.jsx\nimport { describe, it, expect } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport NewsCard from '../NewsCard'\n\ndescribe('NewsCard', () => {\n  const mockArticle = {\n    id: '123',\n    title: 'Test Headline',\n    description: 'Test description',\n    source: { name: 'Test Source' },\n    publishedAt: '2023-01-01T12:00:00Z'\n  }\n\n  it('renders article information correctly', () => {\n    render(<NewsCard article={mockArticle} />)\n    \n    expect(screen.getByText('Test Headline')).toBeInTheDocument()\n    expect(screen.getByText('Test description')).toBeInTheDocument()\n    expect(screen.getByText('Test Source')).toBeInTheDocument()\n    expect(screen.getByText(/Jan 1, 2023/)).toBeInTheDocument()\n  })\n\n  it('calls onSelect when clicked', async () => {\n    const user = userEvent.setup()\n    const mockOnSelect = vi.fn()\n    \n    render(<NewsCard article={mockArticle} onSelect={mockOnSelect} />)\n    \n    await user.click(screen.getByRole('article'))\n    \n    expect(mockOnSelect).toHaveBeenCalledWith(mockArticle)\n  })\n\n  it('displays loading state correctly', () => {\n    render(<NewsCard isLoading={true} />)\n    \n    expect(screen.getByTestId('news-card-skeleton')).toBeInTheDocument()\n  })\n\n  it('is accessible', () => {\n    const { container } = render(<NewsCard article={mockArticle} />)\n    \n    expect(container).toBeAccessible()\n  })\n})\n```\n\n2. Test more complex components with state:\n```javascript\n// src/components/__tests__/CartoonGenerator.test.jsx\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\nimport { render, screen, waitFor } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport CartoonGenerator from '../CartoonGenerator'\nimport { useCartoonStore } from '../../stores/cartoonStore'\n\n// Mock the store\nvi.mock('../../stores/cartoonStore', () => ({\n  useCartoonStore: vi.fn()\n}))\n\ndescribe('CartoonGenerator', () => {\n  const mockGenerateConcept = vi.fn()\n  const mockGenerateImage = vi.fn()\n  \n  beforeEach(() => {\n    useCartoonStore.mockReturnValue({\n      concept: null,\n      image: null,\n      isLoading: false,\n      error: null,\n      generateConcept: mockGenerateConcept,\n      generateImage: mockGenerateImage\n    })\n  })\n\n  it('renders the initial state correctly', () => {\n    render(<CartoonGenerator article={{ title: 'Test Article', content: 'Test content' }} />)\n    \n    expect(screen.getByText('Generate Cartoon')).toBeInTheDocument()\n  })\n\n  it('generates concept when button is clicked', async () => {\n    const user = userEvent.setup()\n    render(<CartoonGenerator article={{ title: 'Test Article', content: 'Test content' }} />)\n    \n    await user.click(screen.getByText('Generate Cartoon'))\n    \n    expect(mockGenerateConcept).toHaveBeenCalledWith({ title: 'Test Article', content: 'Test content' })\n  })\n\n  it('displays loading state', () => {\n    useCartoonStore.mockReturnValue({\n      concept: null,\n      image: null,\n      isLoading: true,\n      error: null,\n      generateConcept: mockGenerateConcept,\n      generateImage: mockGenerateImage\n    })\n    \n    render(<CartoonGenerator article={{ title: 'Test Article', content: 'Test content' }} />)\n    \n    expect(screen.getByTestId('loading-spinner')).toBeInTheDocument()\n  })\n\n  it('displays generated concept and allows image generation', async () => {\n    const user = userEvent.setup()\n    useCartoonStore.mockReturnValue({\n      concept: 'Funny cartoon concept',\n      image: null,\n      isLoading: false,\n      error: null,\n      generateConcept: mockGenerateConcept,\n      generateImage: mockGenerateImage\n    })\n    \n    render(<CartoonGenerator article={{ title: 'Test Article', content: 'Test content' }} />)\n    \n    expect(screen.getByText('Funny cartoon concept')).toBeInTheDocument()\n    \n    await user.click(screen.getByText('Generate Image'))\n    \n    expect(mockGenerateImage).toHaveBeenCalledWith('Funny cartoon concept')\n  })\n\n  it('displays error state', () => {\n    useCartoonStore.mockReturnValue({\n      concept: null,\n      image: null,\n      isLoading: false,\n      error: 'Failed to generate concept',\n      generateConcept: mockGenerateConcept,\n      generateImage: mockGenerateImage\n    })\n    \n    render(<CartoonGenerator article={{ title: 'Test Article', content: 'Test content' }} />)\n    \n    expect(screen.getByText('Failed to generate concept')).toBeInTheDocument()\n  })\n})\n```\n\n3. Create integration tests for component-store interactions:\n```javascript\n// src/integration/__tests__/NewsFlow.test.jsx\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\nimport { render, screen, waitFor } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport { rest } from 'msw'\nimport { server } from '../../test/mocks/server'\nimport NewsPage from '../../pages/NewsPage'\n\ndescribe('News Flow Integration', () => {\n  beforeEach(() => {\n    // Mock location API\n    server.use(\n      rest.get('/api/location', (req, res, ctx) => {\n        return res(ctx.json({ city: 'New York', country: 'US' }))\n      }),\n      rest.get('/api/news/search', (req, res, ctx) => {\n        return res(ctx.json({\n          articles: [\n            { id: '1', title: 'Test Article 1', description: 'Description 1' },\n            { id: '2', title: 'Test Article 2', description: 'Description 2' }\n          ]\n        }))\n      }),\n      rest.get('/api/article/content', (req, res, ctx) => {\n        return res(ctx.json({ content: 'Full article content' }))\n      })\n    )\n  })\n\n  it('loads news based on detected location', async () => {\n    render(<NewsPage />)\n    \n    // Wait for location detection and news loading\n    await waitFor(() => {\n      expect(screen.getByText('News for New York, US')).toBeInTheDocument()\n    })\n    \n    // Verify articles are displayed\n    expect(screen.getByText('Test Article 1')).toBeInTheDocument()\n    expect(screen.getByText('Test Article 2')).toBeInTheDocument()\n  })\n\n  it('allows selecting an article to view details', async () => {\n    const user = userEvent.setup()\n    render(<NewsPage />)\n    \n    // Wait for news to load\n    await waitFor(() => {\n      expect(screen.getByText('Test Article 1')).toBeInTheDocument()\n    })\n    \n    // Click on an article\n    await user.click(screen.getByText('Test Article 1'))\n    \n    // Verify article content loads\n    await waitFor(() => {\n      expect(screen.getByText('Full article content')).toBeInTheDocument()\n    })\n  })\n\n  it('allows changing location manually', async () => {\n    const user = userEvent.setup()\n    \n    // Mock the API for the new location\n    server.use(\n      rest.get('/api/news/search', (req, res, ctx) => {\n        const location = req.url.searchParams.get('location')\n        if (location === 'London') {\n          return res(ctx.json({\n            articles: [{ id: '3', title: 'London News', description: 'News from London' }]\n          }))\n        }\n        return res(ctx.json({ articles: [] }))\n      })\n    )\n    \n    render(<NewsPage />)\n    \n    // Wait for initial news to load\n    await waitFor(() => {\n      expect(screen.getByText('News for New York, US')).toBeInTheDocument()\n    })\n    \n    // Change location\n    await user.click(screen.getByLabelText('Change location'))\n    await user.type(screen.getByRole('textbox'), 'London')\n    await user.click(screen.getByText('Search'))\n    \n    // Verify new location news loads\n    await waitFor(() => {\n      expect(screen.getByText('London News')).toBeInTheDocument()\n    })\n  })\n})\n```\n\n4. Test responsive behavior:\n```javascript\n// src/components/__tests__/ResponsiveLayout.test.jsx\nimport { describe, it, expect } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport ResponsiveLayout from '../ResponsiveLayout'\n\ndescribe('ResponsiveLayout', () => {\n  it('applies mobile class on small viewport', () => {\n    // Mock small viewport\n    window.innerWidth = 480\n    window.dispatchEvent(new Event('resize'))\n    \n    const { container } = render(<ResponsiveLayout><div>Content</div></ResponsiveLayout>)\n    \n    expect(container.firstChild).toHaveClass('mobile-layout')\n  })\n\n  it('applies desktop class on large viewport', () => {\n    // Mock large viewport\n    window.innerWidth = 1200\n    window.dispatchEvent(new Event('resize'))\n    \n    const { container } = render(<ResponsiveLayout><div>Content</div></ResponsiveLayout>)\n    \n    expect(container.firstChild).toHaveClass('desktop-layout')\n  })\n})\n```\n\n5. Test accessibility features:\n```javascript\n// src/components/__tests__/Accessibility.test.jsx\nimport { describe, it, expect } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport NavigationMenu from '../NavigationMenu'\n\ndescribe('Accessibility', () => {\n  it('supports keyboard navigation', async () => {\n    const user = userEvent.setup()\n    render(<NavigationMenu items={[\n      { id: 1, label: 'Home' },\n      { id: 2, label: 'News' },\n      { id: 3, label: 'Settings' }\n    ]} />)\n    \n    // Tab to first menu item\n    await user.tab()\n    expect(screen.getByText('Home')).toHaveFocus()\n    \n    // Tab to second menu item\n    await user.tab()\n    expect(screen.getByText('News')).toHaveFocus()\n    \n    // Tab to third menu item\n    await user.tab()\n    expect(screen.getByText('Settings')).toHaveFocus()\n  })\n\n  it('has proper ARIA attributes', () => {\n    render(<NavigationMenu items={[\n      { id: 1, label: 'Home' },\n      { id: 2, label: 'News' },\n      { id: 3, label: 'Settings' }\n    ]} />)\n    \n    const nav = screen.getByRole('navigation')\n    expect(nav).toHaveAttribute('aria-label', 'Main Navigation')\n    \n    const menuItems = screen.getAllByRole('menuitem')\n    expect(menuItems).toHaveLength(3)\n    menuItems.forEach(item => {\n      expect(item).toHaveAttribute('aria-label')\n    })\n  })\n})\n```",
        "testStrategy": "1. Use React Testing Library to test components in isolation, focusing on user interactions rather than implementation details.\n2. Test all component states: loading, error, success, and empty states.\n3. Verify that components correctly respond to props and user interactions.\n4. Test accessibility features using jest-axe or similar tools.\n5. Test responsive behavior by mocking different viewport sizes.\n6. For integration tests, use MSW to mock API responses and test complete user flows.\n7. Verify that components correctly integrate with stores and services.\n8. Test error handling and recovery flows.\n9. Ensure all critical user paths are covered in integration tests.\n10. Validate that components meet accessibility standards (WCAG 2.1 AA).",
        "priority": "medium",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Basic Component Tests for UI Elements",
            "description": "Implement unit tests for simple UI components focusing on rendering, props validation, and basic interactions. Test components in isolation to verify they render correctly with different props and respond appropriately to user interactions.",
            "dependencies": [],
            "details": "Create test files for basic UI components like NewsCard, Button, and other simple UI elements. Use React Testing Library to test component rendering, prop validation, and user interactions. Focus on testing component behavior from a user perspective rather than implementation details. Include tests for different component states (default, loading, error) and verify accessibility compliance.\n\nExample implementation:\n```javascript\n// src/components/__tests__/Button.test.jsx\nimport { describe, it, expect } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport Button from '../Button'\n\ndescribe('Button', () => {\n  it('renders with correct text', () => {\n    render(<Button>Click me</Button>)\n    expect(screen.getByRole('button', { name: /click me/i })).toBeInTheDocument()\n  })\n\n  it('calls onClick handler when clicked', async () => {\n    const user = userEvent.setup()\n    const handleClick = vi.fn()\n    \n    render(<Button onClick={handleClick}>Click me</Button>)\n    await user.click(screen.getByRole('button'))\n    \n    expect(handleClick).toHaveBeenCalledTimes(1)\n  })\n\n  it('renders in disabled state when disabled prop is true', () => {\n    render(<Button disabled>Click me</Button>)\n    expect(screen.getByRole('button')).toBeDisabled()\n  })\n\n  it('applies variant classes correctly', () => {\n    const { rerender } = render(<Button variant=\"primary\">Button</Button>)\n    expect(screen.getByRole('button')).toHaveClass('btn-primary')\n    \n    rerender(<Button variant=\"secondary\">Button</Button>)\n    expect(screen.getByRole('button')).toHaveClass('btn-secondary')\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Use React Testing Library to focus on user-centric testing. Test component rendering, props validation, and user interactions. Include tests for different component states and accessibility compliance. Use mock functions to verify event handlers are called correctly."
          },
          {
            "id": 2,
            "title": "Implement Tests for Stateful Components",
            "description": "Create comprehensive tests for complex components that manage state, handle user interactions, and integrate with stores. Test component lifecycle, state transitions, and error handling.",
            "dependencies": [
              "3.1"
            ],
            "details": "Develop tests for complex components like NewsFilter, ArticleViewer, and CartoonGenerator that manage internal state and integrate with stores. Mock store dependencies to isolate component behavior. Test component lifecycle methods, state transitions, and error handling. Verify that components correctly respond to store updates and user interactions.\n\nExample implementation:\n```javascript\n// src/components/__tests__/NewsFilter.test.jsx\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\nimport { render, screen, waitFor } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport NewsFilter from '../NewsFilter'\nimport { useNewsStore } from '../../stores/newsStore'\n\n// Mock the store\nvi.mock('../../stores/newsStore', () => ({\n  useNewsStore: vi.fn()\n}))\n\ndescribe('NewsFilter', () => {\n  const mockSetCategory = vi.fn()\n  const mockSetSearchTerm = vi.fn()\n  \n  beforeEach(() => {\n    useNewsStore.mockReturnValue({\n      categories: ['business', 'technology', 'sports'],\n      selectedCategory: 'business',\n      searchTerm: '',\n      setCategory: mockSetCategory,\n      setSearchTerm: mockSetSearchTerm\n    })\n  })\n\n  it('renders all available categories', () => {\n    render(<NewsFilter />)\n    \n    expect(screen.getByRole('button', { name: /business/i })).toBeInTheDocument()\n    expect(screen.getByRole('button', { name: /technology/i })).toBeInTheDocument()\n    expect(screen.getByRole('button', { name: /sports/i })).toBeInTheDocument()\n  })\n\n  it('highlights the selected category', () => {\n    render(<NewsFilter />)\n    \n    const businessButton = screen.getByRole('button', { name: /business/i })\n    expect(businessButton).toHaveClass('selected')\n  })\n\n  it('calls setCategory when a category is clicked', async () => {\n    const user = userEvent.setup()\n    render(<NewsFilter />)\n    \n    await user.click(screen.getByRole('button', { name: /technology/i }))\n    \n    expect(mockSetCategory).toHaveBeenCalledWith('technology')\n  })\n\n  it('updates search term on input change', async () => {\n    const user = userEvent.setup()\n    render(<NewsFilter />)\n    \n    await user.type(screen.getByRole('searchbox'), 'climate')\n    \n    expect(mockSetSearchTerm).toHaveBeenCalledWith('climate')\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Mock store dependencies to isolate component behavior. Test component lifecycle methods, state transitions, and error handling. Verify that components correctly respond to store updates and user interactions. Test both success and error paths."
          },
          {
            "id": 3,
            "title": "Create Integration Tests for Component-Store Interactions",
            "description": "Develop integration tests that verify the correct interaction between components and stores. Test data flow, state management, and component updates in response to store changes.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "Create integration tests that verify components correctly interact with stores. Test data flow between components and stores, state management, and component updates in response to store changes. Use MSW to mock API responses and test the full interaction flow from user action to UI update.\n\nExample implementation:\n```javascript\n// src/integration/__tests__/NewsListIntegration.test.jsx\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\nimport { render, screen, waitFor } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport { rest } from 'msw'\nimport { server } from '../../test/mocks/server'\nimport NewsList from '../../components/NewsList'\n\ndescribe('NewsList Integration', () => {\n  beforeEach(() => {\n    // Reset any runtime handlers\n    server.resetHandlers()\n    \n    // Mock the news API endpoint\n    server.use(\n      rest.get('/api/news', (req, res, ctx) => {\n        const category = req.url.searchParams.get('category')\n        \n        if (category === 'technology') {\n          return res(ctx.json({\n            articles: [\n              { id: '1', title: 'Tech News 1', description: 'Description 1' },\n              { id: '2', title: 'Tech News 2', description: 'Description 2' }\n            ]\n          }))\n        }\n        \n        return res(ctx.json({\n          articles: [\n            { id: '3', title: 'Business News 1', description: 'Description 3' },\n            { id: '4', title: 'Business News 2', description: 'Description 4' }\n          ]\n        }))\n      })\n    )\n  })\n\n  it('loads and displays news articles', async () => {\n    render(<NewsList />)\n    \n    // Wait for articles to load\n    await waitFor(() => {\n      expect(screen.getByText('Business News 1')).toBeInTheDocument()\n    })\n    \n    expect(screen.getByText('Business News 2')).toBeInTheDocument()\n  })\n\n  it('updates articles when category changes', async () => {\n    const user = userEvent.setup()\n    render(<NewsList />)\n    \n    // Wait for initial articles to load\n    await waitFor(() => {\n      expect(screen.getByText('Business News 1')).toBeInTheDocument()\n    })\n    \n    // Change category\n    await user.click(screen.getByRole('button', { name: /technology/i }))\n    \n    // Wait for new articles to load\n    await waitFor(() => {\n      expect(screen.getByText('Tech News 1')).toBeInTheDocument()\n    })\n    \n    expect(screen.getByText('Tech News 2')).toBeInTheDocument()\n    expect(screen.queryByText('Business News 1')).not.toBeInTheDocument()\n  })\n\n  it('displays loading state while fetching articles', async () => {\n    // Mock a delayed response\n    server.use(\n      rest.get('/api/news', (req, res, ctx) => {\n        return res(ctx.delay(300), ctx.json({\n          articles: [{ id: '1', title: 'Delayed News', description: 'Description' }]\n        }))\n      })\n    )\n    \n    render(<NewsList />)\n    \n    // Check for loading state\n    expect(screen.getByTestId('loading-indicator')).toBeInTheDocument()\n    \n    // Wait for articles to load\n    await waitFor(() => {\n      expect(screen.getByText('Delayed News')).toBeInTheDocument()\n    })\n    \n    // Loading indicator should be gone\n    expect(screen.queryByTestId('loading-indicator')).not.toBeInTheDocument()\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Use MSW to mock API responses and test the full interaction flow from user action to UI update. Test loading states, error states, and successful data fetching. Verify that components correctly update in response to store changes. Focus on testing user flows rather than implementation details."
          },
          {
            "id": 4,
            "title": "Implement Responsive Design and Accessibility Tests",
            "description": "Create tests that verify components behave correctly across different viewport sizes and meet accessibility standards. Test keyboard navigation, screen reader compatibility, and responsive layout changes.",
            "dependencies": [
              "3.1"
            ],
            "details": "Develop tests that verify components render correctly at different viewport sizes and meet accessibility standards. Test keyboard navigation, screen reader compatibility, and responsive layout changes. Use testing-library's accessibility utilities to check for common accessibility issues.\n\nExample implementation:\n```javascript\n// src/components/__tests__/ResponsiveNavigation.test.jsx\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\nimport ResponsiveNavigation from '../ResponsiveNavigation'\n\ndescribe('ResponsiveNavigation', () => {\n  let originalInnerWidth\n  \n  beforeEach(() => {\n    originalInnerWidth = window.innerWidth\n    vi.spyOn(window, 'matchMedia')\n  })\n  \n  afterEach(() => {\n    window.innerWidth = originalInnerWidth\n    vi.restoreAllMocks()\n  })\n  \n  it('displays full navigation on desktop', () => {\n    // Mock desktop viewport\n    window.matchMedia.mockImplementation(query => ({\n      matches: query.includes('(min-width: 768px)'),\n      media: query,\n      onchange: null,\n      addListener: vi.fn(),\n      removeListener: vi.fn(),\n      addEventListener: vi.fn(),\n      removeEventListener: vi.fn(),\n      dispatchEvent: vi.fn()\n    }))\n    \n    render(<ResponsiveNavigation />)\n    \n    // All nav items should be visible\n    expect(screen.getByText('Home')).toBeVisible()\n    expect(screen.getByText('News')).toBeVisible()\n    expect(screen.getByText('Settings')).toBeVisible()\n    \n    // Hamburger menu should not be visible\n    expect(screen.queryByLabelText('Open menu')).not.toBeInTheDocument()\n  })\n  \n  it('displays hamburger menu on mobile', () => {\n    // Mock mobile viewport\n    window.matchMedia.mockImplementation(query => ({\n      matches: !query.includes('(min-width: 768px)'),\n      media: query,\n      onchange: null,\n      addListener: vi.fn(),\n      removeListener: vi.fn(),\n      addEventListener: vi.fn(),\n      removeEventListener: vi.fn(),\n      dispatchEvent: vi.fn()\n    }))\n    \n    render(<ResponsiveNavigation />)\n    \n    // Nav items should be hidden initially\n    expect(screen.queryByText('Home')).not.toBeVisible()\n    expect(screen.queryByText('News')).not.toBeVisible()\n    expect(screen.queryByText('Settings')).not.toBeVisible()\n    \n    // Hamburger menu should be visible\n    expect(screen.getByLabelText('Open menu')).toBeInTheDocument()\n  })\n  \n  it('opens mobile menu when hamburger is clicked', async () => {\n    const user = userEvent.setup()\n    \n    // Mock mobile viewport\n    window.matchMedia.mockImplementation(query => ({\n      matches: !query.includes('(min-width: 768px)'),\n      media: query,\n      onchange: null,\n      addListener: vi.fn(),\n      removeListener: vi.fn(),\n      addEventListener: vi.fn(),\n      removeEventListener: vi.fn(),\n      dispatchEvent: vi.fn()\n    }))\n    \n    render(<ResponsiveNavigation />)\n    \n    // Click hamburger menu\n    await user.click(screen.getByLabelText('Open menu'))\n    \n    // Nav items should now be visible\n    expect(screen.getByText('Home')).toBeVisible()\n    expect(screen.getByText('News')).toBeVisible()\n    expect(screen.getByText('Settings')).toBeVisible()\n  })\n  \n  it('supports keyboard navigation', async () => {\n    const user = userEvent.setup()\n    render(<ResponsiveNavigation />)\n    \n    // Tab to first nav item\n    await user.tab()\n    expect(screen.getByText('Home')).toHaveFocus()\n    \n    // Tab to second nav item\n    await user.tab()\n    expect(screen.getByText('News')).toHaveFocus()\n    \n    // Tab to third nav item\n    await user.tab()\n    expect(screen.getByText('Settings')).toHaveFocus()\n  })\n  \n  it('has proper ARIA attributes', () => {\n    render(<ResponsiveNavigation />)\n    \n    const nav = screen.getByRole('navigation')\n    expect(nav).toHaveAttribute('aria-label', 'Main Navigation')\n    \n    const links = screen.getAllByRole('link')\n    links.forEach(link => {\n      expect(link).toHaveAttribute('aria-label')\n    })\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Mock different viewport sizes to test responsive behavior. Use testing-library's accessibility utilities to check for common accessibility issues. Test keyboard navigation to ensure the application is usable without a mouse. Verify that ARIA attributes are correctly applied to elements."
          },
          {
            "id": 5,
            "title": "Create Mock Service Worker Setup for API Testing",
            "description": "Set up Mock Service Worker (MSW) to intercept and mock API requests in tests. Create handlers for all API endpoints used by components and implement test scenarios for success, error, and loading states.",
            "dependencies": [],
            "details": "Set up Mock Service Worker (MSW) to intercept and mock API requests in tests. Create handlers for all API endpoints used by components and implement test scenarios for success, error, and loading states. This will allow testing components that make API calls without hitting actual endpoints.\n\nExample implementation:\n```javascript\n// src/test/mocks/handlers.js\nimport { rest } from 'msw'\n\nexport const handlers = [\n  // News API handlers\n  rest.get('/api/news', (req, res, ctx) => {\n    const category = req.url.searchParams.get('category') || 'general'\n    const searchTerm = req.url.searchParams.get('q') || ''\n    \n    // Mock different responses based on category/search\n    if (category === 'technology') {\n      return res(ctx.json({\n        articles: [\n          { id: '1', title: 'Tech News 1', description: 'Description 1', source: { name: 'Tech Source' }, publishedAt: '2023-01-01T12:00:00Z' },\n          { id: '2', title: 'Tech News 2', description: 'Description 2', source: { name: 'Tech Source' }, publishedAt: '2023-01-02T12:00:00Z' }\n        ]\n      }))\n    }\n    \n    if (searchTerm) {\n      return res(ctx.json({\n        articles: [\n          { id: '3', title: `News about ${searchTerm}`, description: `Description about ${searchTerm}`, source: { name: 'Search Source' }, publishedAt: '2023-01-03T12:00:00Z' }\n        ]\n      }))\n    }\n    \n    return res(ctx.json({\n      articles: [\n        { id: '4', title: 'General News 1', description: 'Description 3', source: { name: 'News Source' }, publishedAt: '2023-01-04T12:00:00Z' },\n        { id: '5', title: 'General News 2', description: 'Description 4', source: { name: 'News Source' }, publishedAt: '2023-01-05T12:00:00Z' }\n      ]\n    }))\n  }),\n  \n  // Article content handler\n  rest.get('/api/article/:id', (req, res, ctx) => {\n    const { id } = req.params\n    \n    if (id === 'error') {\n      return res(ctx.status(500), ctx.json({ error: 'Failed to fetch article' }))\n    }\n    \n    return res(ctx.json({\n      id,\n      title: `Article ${id}`,\n      content: `Full content for article ${id}. This is a longer text that would represent the full article content.`,\n      author: 'Test Author',\n      publishedAt: '2023-01-01T12:00:00Z',\n      source: { name: 'Test Source' }\n    }))\n  }),\n  \n  // Location API handler\n  rest.get('/api/location', (req, res, ctx) => {\n    return res(ctx.json({\n      city: 'New York',\n      country: 'US',\n      coordinates: { lat: 40.7128, lng: -74.0060 }\n    }))\n  }),\n  \n  // Cartoon generation API handlers\n  rest.post('/api/cartoon/concept', (req, res, ctx) => {\n    const { title, content } = req.body\n    \n    if (!title || !content) {\n      return res(ctx.status(400), ctx.json({ error: 'Missing required fields' }))\n    }\n    \n    return res(ctx.json({\n      concept: `A funny cartoon about ${title.substring(0, 20)}...`\n    }))\n  }),\n  \n  rest.post('/api/cartoon/image', (req, res, ctx) => {\n    const { concept } = req.body\n    \n    if (!concept) {\n      return res(ctx.status(400), ctx.json({ error: 'Missing concept' }))\n    }\n    \n    return res(ctx.json({\n      imageUrl: 'https://example.com/mock-cartoon-image.png'\n    }))\n  })\n]\n\n// src/test/mocks/server.js\nimport { setupServer } from 'msw/node'\nimport { handlers } from './handlers'\n\nexport const server = setupServer(...handlers)\n\n// src/test/setup.js\nimport { server } from './mocks/server'\nimport '@testing-library/jest-dom'\n\n// Establish API mocking before all tests\nbeforeAll(() => server.listen())\n\n// Reset any request handlers that we may add during the tests\nafterEach(() => server.resetHandlers())\n\n// Clean up after the tests are finished\nafterAll(() => server.close())\n```",
            "status": "pending",
            "testStrategy": "Create handlers for all API endpoints used by components. Implement test scenarios for success, error, and loading states. Use request parameters to return different mock responses based on the request. Test edge cases like network errors and invalid responses."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement End-to-End and API Tests",
        "description": "Create comprehensive end-to-end tests for critical user journeys and API tests for backend endpoints using Playwright. Validate cross-browser compatibility and mobile responsiveness.",
        "details": "1. Set up E2E test structure:\n```javascript\n// e2e/fixtures/setup.js\nimport { test as base } from '@playwright/test'\n\nexport const test = base.extend({\n  // Custom fixture to log in before tests\n  authenticatedPage: async ({ page }, use) => {\n    // Set up any required state (cookies, local storage, etc.)\n    await page.goto('/')\n    await page.evaluate(() => {\n      localStorage.setItem('preferences', JSON.stringify({ theme: 'light', location: 'New York' }))\n    })\n    await use(page)\n  }\n})\n```\n\n2. Create E2E tests for location detection and news fetching:\n```javascript\n// e2e/location-news.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Location and News Features', () => {\n  test('automatically detects location and loads relevant news', async ({ page }) => {\n    // Mock geolocation API\n    await page.route('**/api/location', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ city: 'San Francisco', country: 'US' })\n      })\n    })\n    \n    await page.goto('/')\n    \n    // Verify location is displayed\n    await expect(page.locator('[data-testid=\"location-display\"]')).toContainText('San Francisco, US')\n    \n    // Verify news articles are loaded\n    await expect(page.locator('[data-testid=\"news-list\"]')).toBeVisible()\n    await expect(page.locator('[data-testid=\"news-card\"]')).toHaveCount.greaterThan(0)\n  })\n\n  test('allows manual location entry', async ({ page }) => {\n    await page.goto('/')\n    \n    // Click location change button\n    await page.click('[data-testid=\"change-location-button\"]')\n    \n    // Enter new location\n    await page.fill('[data-testid=\"location-input\"]', 'Tokyo')\n    await page.click('[data-testid=\"search-button\"]')\n    \n    // Verify new location is displayed\n    await expect(page.locator('[data-testid=\"location-display\"]')).toContainText('Tokyo')\n    \n    // Verify news is updated\n    await expect(page.locator('[data-testid=\"news-list\"]')).toBeVisible()\n  })\n})\n```\n\n3. Create E2E tests for cartoon generation flow:\n```javascript\n// e2e/cartoon-generation.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Cartoon Generation', () => {\n  test('generates cartoon concept from news article', async ({ page }) => {\n    // Mock API responses\n    await page.route('**/api/news/search', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({\n          articles: [{\n            id: '1',\n            title: 'Test Article',\n            description: 'This is a test article for cartoon generation'\n          }]\n        })\n      })\n    })\n    \n    await page.route('**/api/article/content', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ content: 'Full article content for testing' })\n      })\n    })\n    \n    await page.route('**/api/gemini/concept', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ concept: 'A funny cartoon about testing' })\n      })\n    })\n    \n    await page.goto('/')\n    \n    // Select an article\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    \n    // Verify article detail view\n    await expect(page.locator('[data-testid=\"article-content\"]')).toBeVisible()\n    \n    // Generate cartoon concept\n    await page.click('[data-testid=\"generate-cartoon-button\"]')\n    \n    // Verify concept is displayed\n    await expect(page.locator('[data-testid=\"cartoon-concept\"]')).toContainText('A funny cartoon about testing')\n  })\n\n  test('generates image from concept', async ({ page }) => {\n    // Mock API responses including image generation\n    await page.route('**/api/gemini/image', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ imageUrl: 'https://example.com/test-image.jpg' })\n      })\n    })\n    \n    // Set up page with concept already generated\n    await page.goto('/')\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    await page.click('[data-testid=\"generate-cartoon-button\"]')\n    \n    // Generate image\n    await page.click('[data-testid=\"generate-image-button\"]')\n    \n    // Verify image is displayed\n    await expect(page.locator('[data-testid=\"cartoon-image\"]')).toBeVisible()\n    await expect(page.locator('[data-testid=\"cartoon-image\"] img')).toHaveAttribute('src', 'https://example.com/test-image.jpg')\n  })\n\n  test('handles rate limiting', async ({ page }) => {\n    // Mock rate limit exceeded response\n    await page.route('**/api/gemini/image', async route => {\n      await route.fulfill({\n        status: 429,\n        body: JSON.stringify({ error: 'Rate limit exceeded. Try again later.' })\n      })\n    })\n    \n    // Set up page with concept already generated\n    await page.goto('/')\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    await page.click('[data-testid=\"generate-cartoon-button\"]')\n    \n    // Try to generate image\n    await page.click('[data-testid=\"generate-image-button\"]')\n    \n    // Verify rate limit error is displayed\n    await expect(page.locator('[data-testid=\"error-message\"]')).toContainText('Rate limit exceeded')\n  })\n})\n```\n\n4. Create E2E tests for settings persistence:\n```javascript\n// e2e/settings-persistence.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Settings Persistence', () => {\n  test('saves and restores user preferences', async ({ page }) => {\n    await page.goto('/')\n    \n    // Open settings\n    await page.click('[data-testid=\"settings-button\"]')\n    \n    // Change theme\n    await page.click('[data-testid=\"theme-selector\"] [value=\"dark\"]')\n    \n    // Save settings\n    await page.click('[data-testid=\"save-settings\"]')\n    \n    // Verify theme is applied\n    await expect(page.locator('body')).toHaveClass(/dark-theme/)\n    \n    // Reload page\n    await page.reload()\n    \n    // Verify settings persisted\n    await expect(page.locator('body')).toHaveClass(/dark-theme/)\n  })\n})\n```\n\n5. Create API tests:\n```javascript\n// e2e/api.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('API Endpoints', () => {\n  test('news search endpoint returns correct data', async ({ request }) => {\n    const response = await request.get('/api/news/search?location=London')\n    \n    expect(response.status()).toBe(200)\n    const data = await response.json()\n    expect(data).toHaveProperty('articles')\n    expect(Array.isArray(data.articles)).toBe(true)\n  })\n\n  test('article content endpoint returns article data', async ({ request }) => {\n    const response = await request.get('/api/article/content?id=test-article-id')\n    \n    expect(response.status()).toBe(200)\n    const data = await response.json()\n    expect(data).toHaveProperty('content')\n  })\n\n  test('handles invalid requests properly', async ({ request }) => {\n    const response = await request.get('/api/news/search') // Missing required parameter\n    \n    expect(response.status()).toBe(400)\n    const data = await response.json()\n    expect(data).toHaveProperty('error')\n  })\n\n  test('respects CORS headers', async ({ request }) => {\n    const response = await request.get('/api/news/search?location=London', {\n      headers: {\n        'Origin': 'https://example.com'\n      }\n    })\n    \n    expect(response.headers()['access-control-allow-origin']).toBeTruthy()\n  })\n})\n```\n\n6. Test cross-browser compatibility:\n```javascript\n// playwright.config.js (updated)\nexport default {\n  // ... other config\n  projects: [\n    { name: 'chromium', use: { browserName: 'chromium' } },\n    { name: 'firefox', use: { browserName: 'firefox' } },\n    { name: 'webkit', use: { browserName: 'webkit' } },\n    { name: 'mobile chrome', use: { browserName: 'chromium', viewport: { width: 390, height: 844 }, deviceScaleFactor: 2 } },\n    { name: 'mobile safari', use: { browserName: 'webkit', viewport: { width: 390, height: 844 }, deviceScaleFactor: 2 } }\n  ],\n}\n```\n\n7. Create visual regression tests:\n```javascript\n// e2e/visual.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Visual Regression', () => {\n  test('news page looks correct', async ({ page }) => {\n    await page.goto('/')\n    \n    // Wait for content to load\n    await page.waitForSelector('[data-testid=\"news-card\"]')\n    \n    // Take screenshot and compare\n    await expect(page).toHaveScreenshot('news-page.png')\n  })\n\n  test('article detail page looks correct', async ({ page }) => {\n    // Mock API responses\n    await page.route('**/api/news/search', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({\n          articles: [{\n            id: '1',\n            title: 'Test Article',\n            description: 'This is a test article'\n          }]\n        })\n      })\n    })\n    \n    await page.route('**/api/article/content', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ content: 'Full article content for testing' })\n      })\n    })\n    \n    await page.goto('/')\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    \n    // Wait for content to load\n    await page.waitForSelector('[data-testid=\"article-content\"]')\n    \n    // Take screenshot and compare\n    await expect(page).toHaveScreenshot('article-detail.png')\n  })\n})\n```",
        "testStrategy": "1. Use Playwright to create end-to-end tests that simulate real user interactions across different browsers.\n2. Mock API responses to create consistent test scenarios and test edge cases.\n3. Test all critical user journeys identified in the PRD.\n4. Validate that the application works correctly across different browsers (Chrome, Firefox, Safari).\n5. Test mobile responsiveness by using different viewport sizes.\n6. Create API tests to verify backend endpoints function correctly.\n7. Test error handling and recovery flows.\n8. Implement visual regression testing to catch unexpected UI changes.\n9. Test performance aspects like loading times and responsiveness.\n10. Verify that user preferences are correctly persisted between sessions.",
        "priority": "medium",
        "dependencies": [
          1,
          2,
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up E2E Test Framework and Configuration",
            "description": "Configure Playwright for end-to-end testing, including browser configurations, test fixtures, and environment setup for different platforms.",
            "dependencies": [],
            "details": "1. Install Playwright and configure project settings:\n```javascript\n// playwright.config.js\nexport default {\n  testDir: './e2e',\n  timeout: 30000,\n  retries: 2,\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure'\n  },\n  projects: [\n    { name: 'chromium', use: { browserName: 'chromium' } },\n    { name: 'firefox', use: { browserName: 'firefox' } },\n    { name: 'webkit', use: { browserName: 'webkit' } },\n    { name: 'mobile chrome', use: { browserName: 'chromium', viewport: { width: 390, height: 844 }, deviceScaleFactor: 2 } },\n    { name: 'mobile safari', use: { browserName: 'webkit', viewport: { width: 390, height: 844 }, deviceScaleFactor: 2 } }\n  ],\n  reporter: [['html'], ['json', { outputFile: 'test-results/e2e-results.json' }]]\n}\n```\n\n2. Create test fixtures and utilities for common operations:\n```javascript\n// e2e/fixtures/setup.js\nimport { test as base } from '@playwright/test'\n\nexport const test = base.extend({\n  // Custom fixture to log in before tests\n  authenticatedPage: async ({ page }, use) => {\n    // Set up any required state (cookies, local storage, etc.)\n    await page.goto('/')\n    await page.evaluate(() => {\n      localStorage.setItem('preferences', JSON.stringify({ theme: 'light', location: 'New York' }))\n    })\n    await use(page)\n  },\n  // Custom fixture for mobile testing\n  mobilePage: async ({ page }, use) => {\n    // Configure for mobile viewport if not already set in project config\n    await page.setViewportSize({ width: 390, height: 844 })\n    await use(page)\n  }\n})\n```\n\n3. Set up API mocking utilities:\n```javascript\n// e2e/utils/api-mocks.js\nexport async function mockLocationAPI(page, location) {\n  await page.route('**/api/location', async route => {\n    await route.fulfill({\n      status: 200,\n      body: JSON.stringify(location)\n    })\n  })\n}\n\nexport async function mockNewsAPI(page, articles) {\n  await page.route('**/api/news/search**', async route => {\n    await route.fulfill({\n      status: 200,\n      body: JSON.stringify({ articles })\n    })\n  })\n}\n```",
            "status": "pending",
            "testStrategy": "Verify configuration by running a simple smoke test that confirms Playwright can launch browsers and access the application. Test fixtures by creating a simple test that uses each fixture and confirms it works as expected."
          },
          {
            "id": 2,
            "title": "Implement Core User Journey E2E Tests",
            "description": "Create end-to-end tests for the main user flows including location detection, news browsing, and article viewing.",
            "dependencies": [
              "4.1"
            ],
            "details": "1. Create tests for location detection and news browsing:\n```javascript\n// e2e/location-news.spec.js\nimport { test, expect } from './fixtures/setup'\nimport { mockLocationAPI, mockNewsAPI } from './utils/api-mocks'\n\ntest.describe('Location and News Features', () => {\n  test('automatically detects location and loads relevant news', async ({ page }) => {\n    // Mock geolocation API\n    await mockLocationAPI(page, { city: 'San Francisco', country: 'US' })\n    \n    await page.goto('/')\n    \n    // Verify location is displayed\n    await expect(page.locator('[data-testid=\"location-display\"]')).toContainText('San Francisco, US')\n    \n    // Verify news articles are loaded\n    await expect(page.locator('[data-testid=\"news-list\"]')).toBeVisible()\n    await expect(page.locator('[data-testid=\"news-card\"]')).toHaveCount.greaterThan(0)\n  })\n\n  test('allows manual location entry', async ({ page }) => {\n    await page.goto('/')\n    \n    // Click location change button\n    await page.click('[data-testid=\"change-location-button\"]')\n    \n    // Enter new location\n    await page.fill('[data-testid=\"location-input\"]', 'Tokyo')\n    await page.click('[data-testid=\"search-button\"]')\n    \n    // Verify new location is displayed\n    await expect(page.locator('[data-testid=\"location-display\"]')).toContainText('Tokyo')\n    \n    // Verify news is updated\n    await expect(page.locator('[data-testid=\"news-list\"]')).toBeVisible()\n  })\n  \n  test('displays article details when clicking on news card', async ({ page }) => {\n    // Mock news API\n    await mockNewsAPI(page, [{\n      id: 'test-article-1',\n      title: 'Test Headline',\n      description: 'Test description',\n      source: { name: 'Test Source' },\n      publishedAt: '2023-01-01T12:00:00Z'\n    }])\n    \n    await page.goto('/')\n    \n    // Click on news card\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    \n    // Verify article detail view\n    await expect(page.locator('[data-testid=\"article-title\"]')).toContainText('Test Headline')\n    await expect(page.locator('[data-testid=\"article-content\"]')).toBeVisible()\n  })\n})\n```\n\n2. Create tests for settings and preferences:\n```javascript\n// e2e/settings-persistence.spec.js\nimport { test, expect } from './fixtures/setup'\n\ntest.describe('Settings Persistence', () => {\n  test('saves and restores user preferences', async ({ page }) => {\n    await page.goto('/')\n    \n    // Open settings\n    await page.click('[data-testid=\"settings-button\"]')\n    \n    // Change theme\n    await page.click('[data-testid=\"theme-selector\"] [value=\"dark\"]')\n    \n    // Save settings\n    await page.click('[data-testid=\"save-settings\"]')\n    \n    // Verify theme is applied\n    await expect(page.locator('body')).toHaveClass(/dark-theme/)\n    \n    // Reload page\n    await page.reload()\n    \n    // Verify settings persisted\n    await expect(page.locator('body')).toHaveClass(/dark-theme/)\n  })\n  \n  test('allows changing news preferences', async ({ page }) => {\n    await page.goto('/')\n    \n    // Open settings\n    await page.click('[data-testid=\"settings-button\"]')\n    \n    // Change news category preference\n    await page.selectOption('[data-testid=\"category-selector\"]', 'technology')\n    \n    // Save settings\n    await page.click('[data-testid=\"save-settings\"]')\n    \n    // Verify news is updated with technology category\n    await expect(page.locator('[data-testid=\"active-category\"]')).toContainText('Technology')\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Run tests across all configured browsers to verify cross-browser compatibility. Test both desktop and mobile configurations to ensure responsive behavior works correctly. Verify that tests pass consistently and aren't affected by timing issues."
          },
          {
            "id": 3,
            "title": "Implement Cartoon Generation E2E Tests",
            "description": "Create end-to-end tests for the cartoon generation flow, including concept generation, image creation, and error handling.",
            "dependencies": [
              "4.1"
            ],
            "details": "1. Create tests for the cartoon generation flow:\n```javascript\n// e2e/cartoon-generation.spec.js\nimport { test, expect } from './fixtures/setup'\n\ntest.describe('Cartoon Generation', () => {\n  test.beforeEach(async ({ page }) => {\n    // Mock API responses\n    await page.route('**/api/news/search', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({\n          articles: [{\n            id: '1',\n            title: 'Test Article',\n            description: 'This is a test article for cartoon generation'\n          }]\n        })\n      })\n    })\n    \n    await page.route('**/api/article/content', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ content: 'Full article content for testing' })\n      })\n    })\n  })\n  \n  test('generates cartoon concept from news article', async ({ page }) => {\n    await page.route('**/api/gemini/concept', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ concept: 'A funny cartoon about testing' })\n      })\n    })\n    \n    await page.goto('/')\n    \n    // Select an article\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    \n    // Verify article detail view\n    await expect(page.locator('[data-testid=\"article-content\"]')).toBeVisible()\n    \n    // Generate cartoon concept\n    await page.click('[data-testid=\"generate-cartoon-button\"]')\n    \n    // Verify concept is displayed\n    await expect(page.locator('[data-testid=\"cartoon-concept\"]')).toContainText('A funny cartoon about testing')\n  })\n\n  test('generates image from concept', async ({ page }) => {\n    // Mock concept generation API\n    await page.route('**/api/gemini/concept', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ concept: 'A funny cartoon about testing' })\n      })\n    })\n    \n    // Mock image generation API\n    await page.route('**/api/gemini/image', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ imageUrl: 'https://example.com/test-image.jpg' })\n      })\n    })\n    \n    await page.goto('/')\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    await page.click('[data-testid=\"generate-cartoon-button\"]')\n    \n    // Generate image\n    await page.click('[data-testid=\"generate-image-button\"]')\n    \n    // Verify image is displayed\n    await expect(page.locator('[data-testid=\"cartoon-image\"]')).toBeVisible()\n    await expect(page.locator('[data-testid=\"cartoon-image\"] img')).toHaveAttribute('src', 'https://example.com/test-image.jpg')\n  })\n\n  test('handles rate limiting and API errors', async ({ page }) => {\n    // Mock concept generation success\n    await page.route('**/api/gemini/concept', async route => {\n      await route.fulfill({\n        status: 200,\n        body: JSON.stringify({ concept: 'A funny cartoon about testing' })\n      })\n    })\n    \n    // Mock rate limit exceeded response\n    await page.route('**/api/gemini/image', async route => {\n      await route.fulfill({\n        status: 429,\n        body: JSON.stringify({ error: 'Rate limit exceeded. Try again later.' })\n      })\n    })\n    \n    await page.goto('/')\n    await page.click('[data-testid=\"news-card\"]:first-child')\n    await page.click('[data-testid=\"generate-cartoon-button\"]')\n    \n    // Try to generate image\n    await page.click('[data-testid=\"generate-image-button\"]')\n    \n    // Verify rate limit error is displayed\n    await expect(page.locator('[data-testid=\"error-message\"]')).toContainText('Rate limit exceeded')\n    \n    // Verify retry button is available\n    await expect(page.locator('[data-testid=\"retry-button\"]')).toBeVisible()\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Test both happy paths and error scenarios. Use API mocking to simulate different API responses including success, rate limiting, and other errors. Verify that the UI correctly displays loading states, success states, and error messages."
          },
          {
            "id": 4,
            "title": "Implement API Tests",
            "description": "Create comprehensive API tests for all backend endpoints, testing response formats, error handling, and edge cases.",
            "dependencies": [
              "4.1"
            ],
            "details": "1. Create API tests for news and location endpoints:\n```javascript\n// e2e/api/news-location.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('News and Location API Endpoints', () => {\n  test('news search endpoint returns correct data structure', async ({ request }) => {\n    const response = await request.get('/api/news/search?location=London')\n    \n    expect(response.status()).toBe(200)\n    const data = await response.json()\n    expect(data).toHaveProperty('articles')\n    expect(Array.isArray(data.articles)).toBe(true)\n    \n    if (data.articles.length > 0) {\n      const article = data.articles[0]\n      expect(article).toHaveProperty('id')\n      expect(article).toHaveProperty('title')\n      expect(article).toHaveProperty('description')\n      expect(article).toHaveProperty('publishedAt')\n      expect(article).toHaveProperty('source')\n    }\n  })\n\n  test('news search handles invalid parameters', async ({ request }) => {\n    const response = await request.get('/api/news/search') // Missing required parameter\n    \n    expect(response.status()).toBe(400)\n    const data = await response.json()\n    expect(data).toHaveProperty('error')\n  })\n\n  test('article content endpoint returns article data', async ({ request }) => {\n    // First get a valid article ID\n    const searchResponse = await request.get('/api/news/search?location=London')\n    const searchData = await searchResponse.json()\n    \n    if (searchData.articles && searchData.articles.length > 0) {\n      const articleId = searchData.articles[0].id\n      const response = await request.get(`/api/article/content?id=${articleId}`)\n      \n      expect(response.status()).toBe(200)\n      const data = await response.json()\n      expect(data).toHaveProperty('content')\n      expect(typeof data.content).toBe('string')\n    } else {\n      test.skip()\n    }\n  })\n\n  test('location API returns valid data', async ({ request }) => {\n    const response = await request.get('/api/location?query=New York')\n    \n    expect(response.status()).toBe(200)\n    const data = await response.json()\n    expect(data).toHaveProperty('city')\n    expect(data).toHaveProperty('country')\n  })\n})\n```\n\n2. Create API tests for Gemini integration endpoints:\n```javascript\n// e2e/api/gemini.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Gemini API Endpoints', () => {\n  test('concept generation endpoint returns valid data', async ({ request }) => {\n    const response = await request.post('/api/gemini/concept', {\n      data: {\n        articleContent: 'This is a test article about climate change and its effects on global economies.'\n      }\n    })\n    \n    expect(response.status()).toBe(200)\n    const data = await response.json()\n    expect(data).toHaveProperty('concept')\n    expect(typeof data.concept).toBe('string')\n  })\n\n  test('image generation endpoint returns valid data', async ({ request }) => {\n    const response = await request.post('/api/gemini/image', {\n      data: {\n        concept: 'A cartoon showing a businessman looking worried while standing on a melting globe'\n      }\n    })\n    \n    expect(response.status()).toBe(200)\n    const data = await response.json()\n    expect(data).toHaveProperty('imageUrl')\n    expect(typeof data.imageUrl).toBe('string')\n    expect(data.imageUrl).toMatch(/^https?:\\/\\//)\n  })\n\n  test('handles invalid input for concept generation', async ({ request }) => {\n    const response = await request.post('/api/gemini/concept', {\n      data: {\n        // Missing required articleContent\n      }\n    })\n    \n    expect(response.status()).toBe(400)\n    const data = await response.json()\n    expect(data).toHaveProperty('error')\n  })\n\n  test('respects CORS headers', async ({ request }) => {\n    const response = await request.get('/api/gemini/concept', {\n      headers: {\n        'Origin': 'https://example.com'\n      }\n    })\n    \n    expect(response.headers()['access-control-allow-origin']).toBeTruthy()\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Test all API endpoints with valid inputs, invalid inputs, and edge cases. Verify response status codes, headers (including CORS), and response body structure. Chain API calls where necessary to test endpoints that depend on data from other endpoints."
          },
          {
            "id": 5,
            "title": "Implement Cross-Browser and Responsive Tests",
            "description": "Create tests that specifically validate the application's behavior across different browsers and screen sizes, focusing on responsive design and browser-specific issues.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "1. Create visual regression tests for different viewports:\n```javascript\n// e2e/visual/responsive.spec.js\nimport { test, expect } from '@playwright/test'\n\n// Define viewport sizes to test\nconst viewports = [\n  { width: 1920, height: 1080, name: 'desktop' },\n  { width: 768, height: 1024, name: 'tablet' },\n  { width: 390, height: 844, name: 'mobile' }\n]\n\nfor (const viewport of viewports) {\n  test.describe(`Visual tests at ${viewport.name} resolution`, () => {\n    test.use({ viewport })\n    \n    test('news page layout is correct', async ({ page }) => {\n      await page.goto('/')\n      \n      // Wait for content to load\n      await page.waitForSelector('[data-testid=\"news-card\"]')\n      \n      // Take screenshot and compare\n      await expect(page).toHaveScreenshot(`news-page-${viewport.name}.png`)\n    })\n\n    test('article detail page layout is correct', async ({ page }) => {\n      // Mock API responses\n      await page.route('**/api/news/search', async route => {\n        await route.fulfill({\n          status: 200,\n          body: JSON.stringify({\n            articles: [{\n              id: '1',\n              title: 'Test Article',\n              description: 'This is a test article'\n            }]\n          })\n        })\n      })\n      \n      await page.route('**/api/article/content', async route => {\n        await route.fulfill({\n          status: 200,\n          body: JSON.stringify({ content: 'Full article content for testing' })\n        })\n      })\n      \n      await page.goto('/')\n      await page.click('[data-testid=\"news-card\"]:first-child')\n      \n      // Wait for content to load\n      await page.waitForSelector('[data-testid=\"article-content\"]')\n      \n      // Take screenshot and compare\n      await expect(page).toHaveScreenshot(`article-detail-${viewport.name}.png`)\n    })\n\n    test('cartoon generation UI is responsive', async ({ page }) => {\n      // Set up mocks for cartoon generation flow\n      await page.route('**/api/news/search', async route => {\n        await route.fulfill({\n          status: 200,\n          body: JSON.stringify({\n            articles: [{\n              id: '1',\n              title: 'Test Article',\n              description: 'This is a test article'\n            }]\n          })\n        })\n      })\n      \n      await page.route('**/api/article/content', async route => {\n        await route.fulfill({\n          status: 200,\n          body: JSON.stringify({ content: 'Full article content for testing' })\n        })\n      })\n      \n      await page.route('**/api/gemini/concept', async route => {\n        await route.fulfill({\n          status: 200,\n          body: JSON.stringify({ concept: 'A funny cartoon about testing' })\n        })\n      })\n      \n      // Navigate to article and generate concept\n      await page.goto('/')\n      await page.click('[data-testid=\"news-card\"]:first-child')\n      await page.click('[data-testid=\"generate-cartoon-button\"]')\n      \n      // Wait for concept to appear\n      await page.waitForSelector('[data-testid=\"cartoon-concept\"]')\n      \n      // Take screenshot and compare\n      await expect(page).toHaveScreenshot(`cartoon-concept-${viewport.name}.png`)\n    })\n  })\n}\n```\n\n2. Create tests for browser-specific features and interactions:\n```javascript\n// e2e/browser-specific.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Browser-specific tests', () => {\n  test('drag and drop works correctly', async ({ page, browserName }) => {\n    test.skip(browserName === 'webkit' && process.platform === 'darwin', 'Drag and drop has known issues in WebKit on macOS')\n    \n    await page.goto('/cartoon-editor')\n    \n    // Test drag and drop functionality\n    const sourceElement = page.locator('[data-testid=\"draggable-item\"]')\n    const targetElement = page.locator('[data-testid=\"drop-zone\"]')\n    \n    await sourceElement.dragTo(targetElement)\n    \n    // Verify the drop was successful\n    await expect(targetElement.locator('[data-testid=\"dropped-item\"]')).toBeVisible()\n  })\n\n  test('touch interactions work on mobile', async ({ page, browserName }) => {\n    // Only run this test on mobile configurations\n    test.skip(page.viewportSize().width >= 768, 'This test is for mobile only')\n    \n    await page.goto('/')\n    \n    // Test swipe gesture on news cards\n    const newsCard = page.locator('[data-testid=\"news-card\"]:first-child')\n    const cardBounds = await newsCard.boundingBox()\n    \n    // Simulate swipe gesture\n    await page.touchscreen.tap(cardBounds.x + cardBounds.width / 2, cardBounds.y + cardBounds.height / 2)\n    await page.touchscreen.move(cardBounds.x + cardBounds.width / 2 - 100, cardBounds.y + cardBounds.height / 2)\n    await page.touchscreen.up()\n    \n    // Verify swipe action (e.g., card shows save/share buttons)\n    await expect(page.locator('[data-testid=\"card-actions\"]')).toBeVisible()\n  })\n\n  test('local storage works across page reloads', async ({ page, browserName }) => {\n    await page.goto('/')\n    \n    // Set a preference\n    await page.evaluate(() => {\n      localStorage.setItem('testPreference', 'testValue')\n    })\n    \n    // Reload the page\n    await page.reload()\n    \n    // Verify preference persisted\n    const storedValue = await page.evaluate(() => localStorage.getItem('testPreference'))\n    expect(storedValue).toBe('testValue')\n  })\n})\n```",
            "status": "pending",
            "testStrategy": "Run tests on all configured browsers to identify browser-specific issues. Test at multiple viewport sizes to verify responsive design works correctly. Use visual regression testing to catch layout issues. Skip tests that are known to fail on specific browser/platform combinations with clear documentation of why they're skipped."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Performance Tests and Documentation",
        "description": "Create performance tests to measure component render performance, bundle size, lazy loading effectiveness, and API response times. Document the testing strategy, patterns, and procedures.",
        "details": "1. Set up performance testing tools:\n```bash\nnpm install --save-dev lighthouse @playwright/test web-vitals size-limit\n```\n\n2. Configure bundle size limits:\n```json\n// package.json\n{\n  \"size-limit\": [\n    {\n      \"path\": \"dist/index.js\",\n      \"limit\": \"250 KB\"\n    },\n    {\n      \"path\": \"dist/index.css\",\n      \"limit\": \"50 KB\"\n    }\n  ]\n}\n```\n\n3. Create component render performance tests:\n```javascript\n// src/performance/__tests__/render-performance.test.js\nimport { describe, it, expect, beforeEach } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport { NewsCard, NewsList, CartoonGenerator } from '../../components'\n\ndescribe('Component Render Performance', () => {\n  beforeEach(() => {\n    vi.useFakeTimers()\n  })\n  \n  it('NewsCard renders within performance budget', () => {\n    const startTime = performance.now()\n    \n    render(<NewsCard article={{\n      id: '1',\n      title: 'Test Article',\n      description: 'Test description',\n      source: { name: 'Test Source' },\n      publishedAt: '2023-01-01T12:00:00Z'\n    }} />)\n    \n    const endTime = performance.now()\n    const renderTime = endTime - startTime\n    \n    expect(renderTime).toBeLessThan(50) // 50ms budget\n  })\n\n  it('NewsList renders large lists efficiently', () => {\n    const articles = Array.from({ length: 50 }, (_, i) => ({\n      id: `${i}`,\n      title: `Article ${i}`,\n      description: `Description ${i}`,\n      source: { name: 'Test Source' },\n      publishedAt: '2023-01-01T12:00:00Z'\n    }))\n    \n    const startTime = performance.now()\n    \n    render(<NewsList articles={articles} />)\n    \n    const endTime = performance.now()\n    const renderTime = endTime - startTime\n    \n    expect(renderTime).toBeLessThan(200) // 200ms budget for 50 items\n  })\n})\n```\n\n4. Create Lighthouse tests with Playwright:\n```javascript\n// e2e/lighthouse.spec.js\nimport { test, expect } from '@playwright/test'\nimport { playAudit } from 'playwright-lighthouse'\n\ntest('homepage passes Lighthouse audits', async ({ browser }) => {\n  const page = await browser.newPage()\n  await page.goto('/')\n  \n  const { lhr } = await playAudit({\n    page,\n    thresholds: {\n      performance: 90,\n      accessibility: 90,\n      'best-practices': 90,\n      seo: 90\n    },\n    port: 9222\n  })\n  \n  expect(lhr.categories.performance.score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories.accessibility.score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories['best-practices'].score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories.seo.score).toBeGreaterThanOrEqual(0.9)\n})\n```\n\n5. Create API response time tests:\n```javascript\n// e2e/api-performance.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('API Performance', () => {\n  test('news search API responds within time budget', async ({ request }) => {\n    const startTime = Date.now()\n    \n    const response = await request.get('/api/news/search?location=London')\n    \n    const endTime = Date.now()\n    const responseTime = endTime - startTime\n    \n    expect(response.status()).toBe(200)\n    expect(responseTime).toBeLessThan(300) // 300ms budget\n  })\n\n  test('article content API responds within time budget', async ({ request }) => {\n    const startTime = Date.now()\n    \n    const response = await request.get('/api/article/content?id=test-article-id')\n    \n    const endTime = Date.now()\n    const responseTime = endTime - startTime\n    \n    expect(response.status()).toBe(200)\n    expect(responseTime).toBeLessThan(200) // 200ms budget\n  })\n})\n```\n\n6. Test lazy loading effectiveness:\n```javascript\n// e2e/lazy-loading.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest('lazy loaded components load only when needed', async ({ page }) => {\n  // Track network requests\n  const requests = []\n  page.on('request', request => requests.push(request))\n  \n  await page.goto('/')\n  \n  // Get initial chunk count\n  const initialChunks = requests.filter(r => r.url().includes('chunk')).length\n  \n  // Navigate to a page with lazy-loaded components\n  await page.click('[data-testid=\"settings-button\"]')\n  \n  // Check that new chunks were loaded\n  const finalChunks = requests.filter(r => r.url().includes('chunk')).length\n  \n  expect(finalChunks).toBeGreaterThan(initialChunks)\n})\n```\n\n7. Create memory usage tests:\n```javascript\n// e2e/memory-usage.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest('application maintains reasonable memory usage', async ({ page }) => {\n  await page.goto('/')\n  \n  // Get initial memory usage\n  const initialMemory = await page.evaluate(() => performance.memory.usedJSHeapSize)\n  \n  // Perform memory-intensive operations\n  for (let i = 0; i < 10; i++) {\n    // Load articles, generate cartoons, etc.\n    await page.click('[data-testid=\"refresh-button\"]')\n    await page.waitForTimeout(500)\n  }\n  \n  // Get final memory usage\n  const finalMemory = await page.evaluate(() => performance.memory.usedJSHeapSize)\n  \n  // Check for memory leaks (should not increase by more than 50%)\n  expect(finalMemory).toBeLessThan(initialMemory * 1.5)\n})\n```\n\n8. Create test documentation:\n```markdown\n# News Cartoon Application Testing Strategy\n\n## Overview\nThis document outlines the testing strategy for the News Cartoon application, including the types of tests, coverage goals, and best practices.\n\n## Test Types\n\n### Unit Tests\n- **Purpose**: Test individual functions, services, and stores in isolation\n- **Tools**: Vitest, React Testing Library\n- **Coverage Goal**: 80%+ for all modules\n- **Running**: `npm run test`\n\n### Component Tests\n- **Purpose**: Test React components in isolation\n- **Tools**: React Testing Library, Testing Library User Event\n- **Coverage Goal**: All components tested for props, state, and interactions\n- **Running**: `npm run test:components`\n\n### Integration Tests\n- **Purpose**: Test interactions between components, stores, and services\n- **Tools**: Vitest, React Testing Library, MSW\n- **Coverage Goal**: All critical flows covered\n- **Running**: `npm run test:integration`\n\n### End-to-End Tests\n- **Purpose**: Test complete user journeys\n- **Tools**: Playwright\n- **Coverage Goal**: All critical user paths covered\n- **Running**: `npm run test:e2e`\n\n### Performance Tests\n- **Purpose**: Ensure application meets performance targets\n- **Tools**: Lighthouse, size-limit, custom performance tests\n- **Coverage Goal**: All performance metrics within budget\n- **Running**: `npm run test:performance`\n\n## Test Data\n\n### Fixtures\nTest fixtures are located in `src/test/fixtures` and include:\n- Mock articles\n- Mock user preferences\n- Mock API responses\n\n### Mocks\nAPI mocks are defined in `src/test/mocks` using Mock Service Worker (MSW).\n\n## Best Practices\n\n### Writing Tests\n1. Test behavior, not implementation\n2. Use data-testid attributes for test selectors\n3. Mock external dependencies\n4. Test both success and error paths\n5. Keep tests independent and isolated\n\n### Test Organization\n1. Co-locate tests with the code they test\n2. Use descriptive test names\n3. Group related tests with describe blocks\n4. Use beforeEach for common setup\n\n## CI/CD Integration\nTests run automatically on:\n- Pull requests\n- Merges to main branch\n- Nightly builds\n\n## Troubleshooting\n\n### Common Issues\n1. **Flaky tests**: Check for race conditions, add proper waiting\n2. **Slow tests**: Look for unnecessary waits, optimize test setup\n3. **Failed API mocks**: Verify MSW handlers match actual API calls\n\n### Debugging\n1. Use `--debug` flag: `npm run test:e2e -- --debug`\n2. Check test videos and screenshots in `test-results/`\n3. Use console.log in tests (removed in production)\n```\n\n9. Create test running guidelines:\n```markdown\n# Running Tests\n\n## Quick Start\n```bash\n# Run all tests\nnpm run test:all\n\n# Run unit tests\nnpm run test\n\n# Run component tests\nnpm run test:components\n\n# Run E2E tests\nnpm run test:e2e\n\n# Run performance tests\nnpm run test:performance\n```\n\n## Watch Mode\n```bash\n# Run tests in watch mode\nnpm run test:watch\n```\n\n## Coverage Reports\n```bash\n# Generate coverage report\nnpm run test:coverage\n```\nCoverage reports are available in `coverage/index.html`\n\n## Debugging Tests\n\n### Unit and Component Tests\n```bash\n# Run specific test file\nnpm run test src/components/__tests__/NewsCard.test.jsx\n\n# Run tests with specific name\nnpm run test -- -t \"renders article information correctly\"\n```\n\n### E2E Tests\n```bash\n# Run with UI mode\nnpm run test:e2e -- --ui\n\n# Run specific test file\nnpm run test:e2e e2e/location-news.spec.js\n\n# Run on specific browser\nnpm run test:e2e -- --project=firefox\n```\n```",
        "testStrategy": "1. Use Lighthouse and custom performance tests to measure application performance metrics.\n2. Set up bundle size limits with size-limit to prevent performance regressions.\n3. Create tests to measure component render performance and identify bottlenecks.\n4. Test API response times to ensure they meet performance targets.\n5. Validate that lazy loading is working correctly to optimize initial load time.\n6. Monitor memory usage patterns to detect memory leaks.\n7. Document the testing strategy, patterns, and procedures for future reference.\n8. Create guidelines for running and debugging tests.\n9. Set up performance benchmarks to track changes over time.\n10. Ensure all performance tests are included in the CI/CD pipeline.",
        "priority": "low",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up Performance Testing Tools and Bundle Size Limits",
            "description": "Install and configure performance testing tools including Lighthouse, Playwright, web-vitals, and size-limit. Set up bundle size limits in package.json to prevent performance regressions.",
            "dependencies": [],
            "details": "1. Install required performance testing dependencies:\n```bash\nnpm install --save-dev lighthouse @playwright/test web-vitals size-limit\n```\n\n2. Add size-limit configuration to package.json:\n```json\n\"size-limit\": [\n  {\n    \"path\": \"dist/index.js\",\n    \"limit\": \"250 KB\"\n  },\n  {\n    \"path\": \"dist/index.css\",\n    \"limit\": \"50 KB\"\n  }\n]\n```\n\n3. Add performance testing scripts to package.json:\n```json\n\"scripts\": {\n  \"test:performance\": \"npm run test:bundle-size && npm run test:lighthouse\",\n  \"test:bundle-size\": \"size-limit\",\n  \"test:lighthouse\": \"playwright test e2e/lighthouse.spec.js\"\n}\n```\n\n4. Create a basic Lighthouse test configuration file at e2e/lighthouse.spec.js",
            "status": "pending",
            "testStrategy": "Run the bundle size check to verify size-limit is properly configured. Check that all performance testing scripts execute without errors."
          },
          {
            "id": 2,
            "title": "Implement Component Render Performance Tests",
            "description": "Create tests to measure and validate the render performance of key React components, ensuring they render within specified time budgets.",
            "dependencies": [
              "5.1"
            ],
            "details": "1. Create a performance test directory structure:\n```bash\nmkdir -p src/performance/__tests__\n```\n\n2. Implement render performance tests for key components:\n```javascript\n// src/performance/__tests__/render-performance.test.js\nimport { describe, it, expect, beforeEach } from 'vitest'\nimport { render, screen } from '@testing-library/react'\nimport { NewsCard, NewsList, CartoonGenerator } from '../../components'\n\ndescribe('Component Render Performance', () => {\n  beforeEach(() => {\n    vi.useFakeTimers()\n  })\n  \n  it('NewsCard renders within performance budget', () => {\n    const startTime = performance.now()\n    \n    render(<NewsCard article={{\n      id: '1',\n      title: 'Test Article',\n      description: 'Test description',\n      source: { name: 'Test Source' },\n      publishedAt: '2023-01-01T12:00:00Z'\n    }} />)\n    \n    const endTime = performance.now()\n    const renderTime = endTime - startTime\n    \n    expect(renderTime).toBeLessThan(50) // 50ms budget\n  })\n\n  it('NewsList renders large lists efficiently', () => {\n    const articles = Array.from({ length: 50 }, (_, i) => ({\n      id: `${i}`,\n      title: `Article ${i}`,\n      description: `Description ${i}`,\n      source: { name: 'Test Source' },\n      publishedAt: '2023-01-01T12:00:00Z'\n    }))\n    \n    const startTime = performance.now()\n    \n    render(<NewsList articles={articles} />)\n    \n    const endTime = performance.now()\n    const renderTime = endTime - startTime\n    \n    expect(renderTime).toBeLessThan(200) // 200ms budget for 50 items\n  })\n\n  it('CartoonGenerator renders within performance budget', () => {\n    const startTime = performance.now()\n    \n    render(<CartoonGenerator article={{\n      id: '1',\n      title: 'Test Article',\n      description: 'Test description',\n      content: 'Test content that is longer for cartoon generation'\n    }} />)\n    \n    const endTime = performance.now()\n    const renderTime = endTime - startTime\n    \n    expect(renderTime).toBeLessThan(100) // 100ms budget\n  })\n})\n```\n\n3. Add a script to run component performance tests:\n```json\n\"scripts\": {\n  \"test:component-performance\": \"vitest run src/performance/__tests__/render-performance.test.js\"\n}\n```",
            "status": "pending",
            "testStrategy": "Run tests with different component sizes and props to identify performance bottlenecks. Adjust time budgets based on actual performance to set realistic but challenging targets."
          },
          {
            "id": 3,
            "title": "Create API Response Time and Lazy Loading Tests",
            "description": "Implement tests to measure API response times and verify that lazy-loaded components are only loaded when needed, reducing initial page load time.",
            "dependencies": [
              "5.1"
            ],
            "details": "1. Create API response time tests:\n```javascript\n// e2e/api-performance.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest.describe('API Performance', () => {\n  test('news search API responds within time budget', async ({ request }) => {\n    const startTime = Date.now()\n    \n    const response = await request.get('/api/news/search?location=London')\n    \n    const endTime = Date.now()\n    const responseTime = endTime - startTime\n    \n    expect(response.status()).toBe(200)\n    expect(responseTime).toBeLessThan(300) // 300ms budget\n  })\n\n  test('article content API responds within time budget', async ({ request }) => {\n    const startTime = Date.now()\n    \n    const response = await request.get('/api/article/content?id=test-article-id')\n    \n    const endTime = Date.now()\n    const responseTime = endTime - startTime\n    \n    expect(response.status()).toBe(200)\n    expect(responseTime).toBeLessThan(200) // 200ms budget\n  })\n\n  test('cartoon generation API responds within time budget', async ({ request }) => {\n    const startTime = Date.now()\n    \n    const response = await request.post('/api/cartoon/generate', {\n      data: {\n        articleContent: 'Test content for cartoon generation'\n      }\n    })\n    \n    const endTime = Date.now()\n    const responseTime = endTime - startTime\n    \n    expect(response.status()).toBe(200)\n    expect(responseTime).toBeLessThan(1000) // 1000ms budget for AI generation\n  })\n})\n```\n\n2. Create lazy loading effectiveness tests:\n```javascript\n// e2e/lazy-loading.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest('lazy loaded components load only when needed', async ({ page }) => {\n  // Track network requests\n  const requests = []\n  page.on('request', request => requests.push(request))\n  \n  await page.goto('/')\n  \n  // Get initial chunk count\n  const initialChunks = requests.filter(r => r.url().includes('chunk')).length\n  \n  // Navigate to a page with lazy-loaded components\n  await page.click('[data-testid=\"settings-button\"]')\n  \n  // Check that new chunks were loaded\n  const finalChunks = requests.filter(r => r.url().includes('chunk')).length\n  \n  expect(finalChunks).toBeGreaterThan(initialChunks)\n})\n\ntest('cartoon generator loads only when article is expanded', async ({ page }) => {\n  const requests = []\n  page.on('request', request => requests.push(request))\n  \n  await page.goto('/')\n  \n  // Check initial requests don't include cartoon generator chunk\n  const initialCartoonChunks = requests.filter(r => \n    r.url().includes('chunk') && r.url().includes('cartoon')\n  ).length\n  \n  expect(initialCartoonChunks).toBe(0)\n  \n  // Expand an article to trigger lazy loading\n  await page.click('[data-testid=\"article-item\"]')\n  \n  // Wait for lazy loading\n  await page.waitForTimeout(500)\n  \n  // Check that cartoon generator chunk was loaded\n  const finalCartoonChunks = requests.filter(r => \n    r.url().includes('chunk') && r.url().includes('cartoon')\n  ).length\n  \n  expect(finalCartoonChunks).toBeGreaterThan(0)\n})\n```\n\n3. Add scripts to run these tests:\n```json\n\"scripts\": {\n  \"test:api-performance\": \"playwright test e2e/api-performance.spec.js\",\n  \"test:lazy-loading\": \"playwright test e2e/lazy-loading.spec.js\"\n}\n```",
            "status": "pending",
            "testStrategy": "Run API performance tests against both development and production environments to compare performance. For lazy loading tests, use network throttling to simulate different connection speeds and verify that lazy loading improves initial load time."
          },
          {
            "id": 4,
            "title": "Implement Lighthouse and Memory Usage Tests",
            "description": "Create automated Lighthouse tests to measure overall application performance, accessibility, SEO, and best practices. Implement memory usage tests to detect memory leaks.",
            "dependencies": [
              "5.1"
            ],
            "details": "1. Create Lighthouse tests with Playwright:\n```javascript\n// e2e/lighthouse.spec.js\nimport { test, expect } from '@playwright/test'\nimport { playAudit } from 'playwright-lighthouse'\n\ntest('homepage passes Lighthouse audits', async ({ browser }) => {\n  const page = await browser.newPage()\n  await page.goto('/')\n  \n  const { lhr } = await playAudit({\n    page,\n    thresholds: {\n      performance: 90,\n      accessibility: 90,\n      'best-practices': 90,\n      seo: 90\n    },\n    port: 9222\n  })\n  \n  expect(lhr.categories.performance.score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories.accessibility.score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories['best-practices'].score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories.seo.score).toBeGreaterThanOrEqual(0.9)\n})\n\ntest('article detail page passes Lighthouse audits', async ({ browser }) => {\n  const page = await browser.newPage()\n  await page.goto('/article/test-article-id')\n  \n  const { lhr } = await playAudit({\n    page,\n    thresholds: {\n      performance: 85,\n      accessibility: 90,\n      'best-practices': 90,\n      seo: 90\n    },\n    port: 9222\n  })\n  \n  expect(lhr.categories.performance.score).toBeGreaterThanOrEqual(0.85)\n  expect(lhr.categories.accessibility.score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories['best-practices'].score).toBeGreaterThanOrEqual(0.9)\n  expect(lhr.categories.seo.score).toBeGreaterThanOrEqual(0.9)\n})\n```\n\n2. Create memory usage tests:\n```javascript\n// e2e/memory-usage.spec.js\nimport { test, expect } from '@playwright/test'\n\ntest('application maintains reasonable memory usage', async ({ page }) => {\n  await page.goto('/')\n  \n  // Get initial memory usage\n  const initialMemory = await page.evaluate(() => performance.memory.usedJSHeapSize)\n  \n  // Perform memory-intensive operations\n  for (let i = 0; i < 10; i++) {\n    // Load articles, generate cartoons, etc.\n    await page.click('[data-testid=\"refresh-button\"]')\n    await page.waitForTimeout(500)\n  }\n  \n  // Get final memory usage\n  const finalMemory = await page.evaluate(() => performance.memory.usedJSHeapSize)\n  \n  // Check for memory leaks (should not increase by more than 50%)\n  expect(finalMemory).toBeLessThan(initialMemory * 1.5)\n})\n\ntest('memory usage remains stable after multiple page navigations', async ({ page }) => {\n  await page.goto('/')\n  \n  const initialMemory = await page.evaluate(() => performance.memory.usedJSHeapSize)\n  \n  // Navigate between pages multiple times\n  for (let i = 0; i < 5; i++) {\n    await page.click('[data-testid=\"settings-button\"]')\n    await page.waitForTimeout(300)\n    await page.click('[data-testid=\"home-button\"]')\n    await page.waitForTimeout(300)\n  }\n  \n  const finalMemory = await page.evaluate(() => performance.memory.usedJSHeapSize)\n  \n  // Memory should not grow significantly\n  expect(finalMemory).toBeLessThan(initialMemory * 1.3)\n})\n```\n\n3. Add scripts to run these tests:\n```json\n\"scripts\": {\n  \"test:lighthouse\": \"playwright test e2e/lighthouse.spec.js\",\n  \"test:memory\": \"playwright test e2e/memory-usage.spec.js\"\n}\n```",
            "status": "pending",
            "testStrategy": "Run Lighthouse tests in headless mode for consistent results. For memory tests, run with different browsers to compare memory management. Consider running memory tests with a longer duration to detect slow memory leaks."
          },
          {
            "id": 5,
            "title": "Create Comprehensive Testing Documentation",
            "description": "Document the testing strategy, patterns, procedures, and guidelines for the entire application. Include information on running tests, troubleshooting, and best practices.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "1. Create a main testing documentation file:\n```markdown\n# News Cartoon Application Testing Strategy\n\n## Overview\nThis document outlines the testing strategy for the News Cartoon application, including the types of tests, coverage goals, and best practices.\n\n## Test Types\n\n### Unit Tests\n- **Purpose**: Test individual functions, services, and stores in isolation\n- **Tools**: Vitest, React Testing Library\n- **Coverage Goal**: 80%+ for all modules\n- **Running**: `npm run test`\n\n### Component Tests\n- **Purpose**: Test React components in isolation\n- **Tools**: React Testing Library, Testing Library User Event\n- **Coverage Goal**: All components tested for props, state, and interactions\n- **Running**: `npm run test:components`\n\n### Integration Tests\n- **Purpose**: Test interactions between components, stores, and services\n- **Tools**: Vitest, React Testing Library, MSW\n- **Coverage Goal**: All critical flows covered\n- **Running**: `npm run test:integration`\n\n### End-to-End Tests\n- **Purpose**: Test complete user journeys\n- **Tools**: Playwright\n- **Coverage Goal**: All critical user paths covered\n- **Running**: `npm run test:e2e`\n\n### Performance Tests\n- **Purpose**: Ensure application meets performance targets\n- **Tools**: Lighthouse, size-limit, custom performance tests\n- **Coverage Goal**: All performance metrics within budget\n- **Running**: `npm run test:performance`\n\n## Performance Testing Strategy\n\n### Component Render Performance\n- Each component has a render time budget\n- NewsCard: 50ms\n- NewsList (50 items): 200ms\n- CartoonGenerator: 100ms\n\n### API Response Times\n- News search API: 300ms\n- Article content API: 200ms\n- Cartoon generation API: 1000ms\n\n### Bundle Size Limits\n- Main JS bundle: 250KB\n- CSS: 50KB\n\n### Lighthouse Score Targets\n- Performance: 90+\n- Accessibility: 90+\n- Best Practices: 90+\n- SEO: 90+\n\n### Memory Usage\n- No more than 50% increase after intensive operations\n- No more than 30% increase after multiple page navigations\n\n## Test Data\n\n### Fixtures\nTest fixtures are located in `src/test/fixtures` and include:\n- Mock articles\n- Mock user preferences\n- Mock API responses\n\n### Mocks\nAPI mocks are defined in `src/test/mocks` using Mock Service Worker (MSW).\n\n## Best Practices\n\n### Writing Tests\n1. Test behavior, not implementation\n2. Use data-testid attributes for test selectors\n3. Mock external dependencies\n4. Test both success and error paths\n5. Keep tests independent and isolated\n\n### Test Organization\n1. Co-locate tests with the code they test\n2. Use descriptive test names\n3. Group related tests with describe blocks\n4. Use beforeEach for common setup\n\n## CI/CD Integration\nTests run automatically on:\n- Pull requests\n- Merges to main branch\n- Nightly builds\n\n## Troubleshooting\n\n### Common Issues\n1. **Flaky tests**: Check for race conditions, add proper waiting\n2. **Slow tests**: Look for unnecessary waits, optimize test setup\n3. **Failed API mocks**: Verify MSW handlers match actual API calls\n\n### Debugging\n1. Use `--debug` flag: `npm run test:e2e -- --debug`\n2. Check test videos and screenshots in `test-results/`\n3. Use console.log in tests (removed in production)\n```\n\n2. Create a test running guide:\n```markdown\n# Running Tests\n\n## Quick Start\n```bash\n# Run all tests\nnpm run test:all\n\n# Run unit tests\nnpm run test\n\n# Run component tests\nnpm run test:components\n\n# Run E2E tests\nnpm run test:e2e\n\n# Run performance tests\nnpm run test:performance\n```\n\n## Performance Tests\n```bash\n# Run all performance tests\nnpm run test:performance\n\n# Run bundle size checks\nnpm run test:bundle-size\n\n# Run component render performance tests\nnpm run test:component-performance\n\n# Run API performance tests\nnpm run test:api-performance\n\n# Run lazy loading tests\nnpm run test:lazy-loading\n\n# Run Lighthouse tests\nnpm run test:lighthouse\n\n# Run memory usage tests\nnpm run test:memory\n```\n\n## Watch Mode\n```bash\n# Run tests in watch mode\nnpm run test:watch\n```\n\n## Coverage Reports\n```bash\n# Generate coverage report\nnpm run test:coverage\n```\nCoverage reports are available in `coverage/index.html`\n\n## Debugging Tests\n\n### Unit and Component Tests\n```bash\n# Run specific test file\nnpm run test src/components/__tests__/NewsCard.test.jsx\n\n# Run tests with specific name\nnpm run test -- -t \"renders article information correctly\"\n```\n\n### E2E Tests\n```bash\n# Run with UI mode\nnpm run test:e2e -- --ui\n\n# Run specific test file\nnpm run test:e2e e2e/location-news.spec.js\n\n# Run on specific browser\nnpm run test:e2e -- --project=firefox\n```\n\n### Performance Tests\n```bash\n# Run with verbose logging\nnpm run test:performance -- --debug\n\n# Run with different performance thresholds\nLIGHTHOUSE_PERFORMANCE_THRESHOLD=85 npm run test:lighthouse\n```\n```\n\n3. Create a performance testing specific guide:\n```markdown\n# Performance Testing Guide\n\n## Overview\nThis guide explains how to run, interpret, and maintain the performance tests for the News Cartoon application.\n\n## Running Performance Tests\n\n### Prerequisites\n- Node.js 16+\n- Chrome browser installed (for Lighthouse tests)\n\n### Commands\n```bash\n# Run all performance tests\nnpm run test:performance\n\n# Run individual performance test suites\nnpm run test:bundle-size\nnpm run test:component-performance\nnpm run test:api-performance\nnpm run test:lazy-loading\nnpm run test:lighthouse\nnpm run test:memory\n```\n\n## Interpreting Results\n\n### Bundle Size\nThe size-limit tool will fail the build if bundles exceed the configured limits:\n- Main JS bundle: 250KB\n- CSS: 50KB\n\n### Component Render Performance\nTests will fail if components render slower than:\n- NewsCard: 50ms\n- NewsList (50 items): 200ms\n- CartoonGenerator: 100ms\n\n### API Response Times\nTests will fail if API responses take longer than:\n- News search API: 300ms\n- Article content API: 200ms\n- Cartoon generation API: 1000ms\n\n### Lighthouse Scores\nTests will fail if scores are below:\n- Performance: 90\n- Accessibility: 90\n- Best Practices: 90\n- SEO: 90\n\n### Memory Usage\nTests will fail if memory usage increases by:\n- More than 50% after intensive operations\n- More than 30% after multiple page navigations\n\n## Maintaining Performance Tests\n\n### Adjusting Thresholds\nIf performance tests are consistently failing or passing too easily, adjust thresholds in:\n- `package.json` for bundle size limits\n- Test files for component render times, API response times, etc.\n\n### Adding New Tests\n1. Create test files in appropriate directories\n2. Add new test scripts to package.json\n3. Update documentation\n\n### CI/CD Integration\nPerformance tests run on:\n- Pull requests (bundle size only)\n- Nightly builds (all performance tests)\n\n## Troubleshooting\n\n### Common Issues\n\n#### Inconsistent Lighthouse Scores\n- Run tests in headless mode\n- Ensure consistent network conditions\n- Run multiple times and average results\n\n#### Slow Component Render Times\n- Check for unnecessary re-renders\n- Look for expensive calculations in render path\n- Consider memoization or code splitting\n\n#### Memory Leaks\n- Check for event listeners not being cleaned up\n- Look for large objects being stored in state\n- Verify that components are properly unmounted\n```",
            "status": "pending",
            "testStrategy": "Review documentation with the team to ensure it's comprehensive and accurate. Update documentation as testing strategy evolves. Create a process for regularly reviewing and updating performance thresholds based on real-world usage data."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-11-09T02:17:20.187Z",
      "updated": "2025-11-09T02:37:01.537Z",
      "description": "Tasks for master context"
    }
  },
  "ui-simplification": {
    "tasks": [
      {
        "id": 1,
        "title": "Phase 1: Quick Wins",
        "description": "Implement quick UI improvements that can be done in 1-2 days with immediate impact",
        "details": "Focus on removing visual clutter, simplifying the color scheme, improving mobile touch targets, and implementing smart defaults. These changes should provide immediate improvement with minimal effort.",
        "testStrategy": "Visual regression testing, mobile responsiveness testing, user acceptance testing",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Simplify Color Scheme and Remove Gradients",
            "description": "Remove all gradient backgrounds and simplify the color scheme to a blue/gray palette throughout the application to reduce visual clutter and create a cleaner interface.",
            "dependencies": [],
            "details": "1. Update CSS variables to define a simplified blue/gray color palette\n2. Replace all gradient backgrounds with solid colors\n3. Ensure consistent color application across all UI components\n4. Update button styles to use the new color scheme\n5. Verify contrast ratios meet accessibility standards",
            "status": "pending",
            "testStrategy": "Visual regression testing to compare before/after screenshots; verify color contrast meets WCAG AA standards"
          },
          {
            "id": 2,
            "title": "Implement Smart Default Article Selection",
            "description": "Modify the article loading logic to automatically select the top 3 articles with the highest humor scores when news content loads.",
            "dependencies": [],
            "details": "1. Update the article loading function to sort articles by humor score\n2. Modify the selection logic to automatically check the top 3 highest-scoring articles\n3. Ensure the UI reflects these pre-selected articles\n4. Add visual indicators for pre-selected articles\n5. Maintain the ability for users to change selections manually",
            "status": "pending",
            "testStrategy": "Unit tests for sorting and selection logic; integration tests to verify correct articles are selected on page load"
          },
          {
            "id": 3,
            "title": "Set Default Panel Count and Simplify UI",
            "description": "Set the default panel count to 4 and remove the panel selector from the main UI to simplify the interface and streamline the user experience.",
            "dependencies": [],
            "details": "1. Update the default configuration to set panel count to 4\n2. Remove the panel selector component from the main UI\n3. Add the panel selection option to an advanced settings section if needed\n4. Update any related documentation or tooltips\n5. Ensure the comic generation works correctly with the fixed panel count",
            "status": "pending",
            "testStrategy": "Functional testing to verify comics generate with 4 panels by default; UI verification to confirm panel selector is removed"
          },
          {
            "id": 4,
            "title": "Increase Mobile Touch Targets",
            "description": "Increase all clickable elements to have a minimum height of 44px on mobile devices to improve usability and accessibility on touch screens.",
            "dependencies": [],
            "details": "1. Identify all interactive elements (buttons, links, form controls)\n2. Update CSS to ensure minimum 44px height and appropriate width for touch targets\n3. Add appropriate padding and margins to prevent accidental touches\n4. Test on various mobile device sizes\n5. Ensure changes don't negatively impact desktop layout",
            "status": "pending",
            "testStrategy": "Mobile device testing across different screen sizes; touch accuracy testing; verify no layout issues on desktop"
          },
          {
            "id": 5,
            "title": "Remove Redundant Information",
            "description": "Clean up the UI by removing duplicate summaries, unnecessary metadata, and other redundant information that adds visual clutter without providing value.",
            "dependencies": [],
            "details": "1. Identify all instances of duplicate content (summaries, timestamps, etc.)\n2. Remove redundant article metadata while preserving essential information\n3. Consolidate similar information into single, clear displays\n4. Simplify article preview cards to show only essential details\n5. Update layouts to accommodate the reduced content",
            "status": "pending",
            "testStrategy": "Visual inspection to verify removal of redundant elements; user testing to ensure no critical information was removed"
          }
        ]
      },
      {
        "id": 2,
        "title": "Phase 2: Core Improvements",
        "description": "Implement core UI improvements including wizard interface and workflow optimizations (3-5 days)",
        "details": "Transform the multi-step process into a cleaner wizard interface, add Quick Cartoon mode, implement progressive disclosure, combine related actions, and improve error handling.",
        "testStrategy": "End-to-end workflow testing, usability testing, error scenario testing",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Wizard Interface with Progress Tracking",
            "description": "Create a step-by-step wizard interface that clearly shows the user's progress through the cartoon generation workflow. Include step indicators, progress bar, and navigation controls.",
            "dependencies": [],
            "details": "Develop a wizard component with numbered steps and progress bar at the top. Each step should be a separate view with Next/Back buttons. Store the current step in state and implement navigation logic. Use CSS transitions for smooth step changes. Ensure the wizard is responsive and works on mobile devices.",
            "status": "pending",
            "testStrategy": "Test navigation between steps, verify progress tracking accuracy, ensure responsive design works across devices, and validate that state is preserved when moving between steps."
          },
          {
            "id": 2,
            "title": "Add Quick Cartoon Mode for Trending News",
            "description": "Implement a one-click cartoon generation feature that automatically selects trending news topics and generates cartoons without requiring manual input for each step.",
            "dependencies": [
              "2.1"
            ],
            "details": "Create an API endpoint to fetch trending news topics. Implement a 'Quick Cartoon' button on the dashboard that triggers automatic selection of a trending topic, generates a script, creates characters, and produces the final cartoon. Add a loading indicator during generation and display the result with options to edit or share.",
            "status": "pending",
            "testStrategy": "Test the end-to-end quick generation process, verify trending topics are relevant, measure performance metrics for generation time, and test error handling when API calls fail."
          },
          {
            "id": 3,
            "title": "Implement Progressive Disclosure Pattern",
            "description": "Modify the UI to collapse completed sections and only show relevant information at each step, reducing cognitive load and simplifying the interface.",
            "dependencies": [
              "2.1"
            ],
            "details": "Add collapsible sections for each completed step in the wizard. When a step is completed, automatically collapse it and show a summary. Add an expand/collapse toggle for users to review previous steps if needed. Store the expanded/collapsed state in the application state. Ensure smooth animations for collapse/expand actions.",
            "status": "pending",
            "testStrategy": "Verify sections collapse correctly after completion, test that summaries accurately reflect the completed work, ensure expand/collapse functionality works properly, and check that the state is preserved during navigation."
          },
          {
            "id": 4,
            "title": "Combine Concept Selection with Script Generation",
            "description": "Merge the concept selection and script generation steps to reduce the overall number of steps in the workflow and create a more streamlined experience.",
            "dependencies": [
              "2.1",
              "2.3"
            ],
            "details": "Redesign the concept selection UI to include script generation in the same view. As users select a concept, dynamically show script options or a script editor. Implement real-time script generation based on the selected concept. Add preview functionality to show how the script will look with the selected concept. Update the wizard navigation to reflect the combined step.",
            "status": "pending",
            "testStrategy": "Test the combined workflow for usability, verify that script generation works correctly with different concept selections, ensure the preview functionality accurately reflects the final output, and test edge cases with unusual concept selections."
          },
          {
            "id": 5,
            "title": "Improve Error Handling with Inline Messages",
            "description": "Enhance error handling throughout the application with contextual inline error messages and automatic retry functionality for common errors.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3",
              "2.4"
            ],
            "details": "Implement a consistent error handling system that displays inline error messages near the relevant UI elements. Create error message components with appropriate styling for different severity levels. Add automatic retry logic for network-related errors with exponential backoff. Implement a global error boundary to catch unhandled exceptions. Add user-friendly error messages with suggested actions for recovery.",
            "status": "pending",
            "testStrategy": "Test various error scenarios including network failures, validation errors, and server errors. Verify that error messages are clear and actionable. Test automatic retry functionality with simulated network issues. Ensure errors are logged properly for debugging."
          }
        ]
      },
      {
        "id": 3,
        "title": "Phase 3: Advanced Features",
        "description": "Implement advanced features and optimizations (1 week)",
        "details": "Add inline editing capabilities, implement swipe gestures for mobile, optimize performance with lazy loading and caching, improve accessibility with ARIA labels and keyboard navigation, and create an advanced settings panel for power users.",
        "testStrategy": "Performance testing, accessibility testing (WCAG compliance), cross-browser testing, gesture testing on mobile devices",
        "status": "pending",
        "dependencies": [
          1,
          2
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Inline Editing for Scripts",
            "description": "Add the ability to edit script content directly within the viewing interface without requiring users to switch to a separate edit mode.",
            "dependencies": [],
            "details": "Create an editable content system using contentEditable or a rich text editor component. Implement auto-saving functionality that preserves changes after a brief period of inactivity. Add visual indicators to show which elements are editable on hover. Include formatting controls that appear contextually when text is selected. Ensure proper validation and error handling for edited content.",
            "status": "pending",
            "testStrategy": "Unit tests for edit functionality, integration tests for auto-save feature, usability testing with content creators to validate the editing experience."
          },
          {
            "id": 2,
            "title": "Add Swipe Gestures for Mobile Navigation",
            "description": "Implement touch-based swipe gestures to allow mobile users to navigate between steps in the script creation process.",
            "dependencies": [],
            "details": "Integrate a touch gesture library like Hammer.js to detect horizontal swipe actions. Add smooth transitions between steps when swiping left (next) or right (previous). Implement velocity-based animations that respond to the speed of the user's swipe. Include visual indicators during swipe to show the destination. Add haptic feedback for successful navigation events on supported devices.",
            "status": "pending",
            "testStrategy": "Mobile device testing across different screen sizes, gesture recognition accuracy testing, performance testing for animation smoothness."
          },
          {
            "id": 3,
            "title": "Optimize Performance with Lazy Loading and Caching",
            "description": "Improve application performance by implementing lazy loading for content and establishing an effective caching strategy.",
            "dependencies": [],
            "details": "Implement intersection observer API to load content only when it's about to enter the viewport. Set up a service worker to cache static assets and API responses. Add prefetching for likely next steps based on user navigation patterns. Implement image optimization with responsive loading based on device capabilities. Create a memory management system that unloads content that's no longer needed.",
            "status": "pending",
            "testStrategy": "Performance benchmarking before and after implementation, load time measurements, memory usage monitoring, testing on low-end devices to ensure improvements are universal."
          },
          {
            "id": 4,
            "title": "Improve Accessibility with ARIA and Keyboard Navigation",
            "description": "Enhance the application's accessibility by adding proper ARIA attributes and implementing comprehensive keyboard navigation.",
            "dependencies": [],
            "details": "Audit existing components and add appropriate ARIA roles, states, and properties. Implement focus management system that maintains a logical tab order. Create keyboard shortcuts for common actions with a visible shortcut reference. Ensure all interactive elements are keyboard accessible with visible focus states. Add screen reader announcements for dynamic content changes and important notifications.",
            "status": "pending",
            "testStrategy": "Accessibility testing with screen readers (NVDA, JAWS, VoiceOver), keyboard-only navigation testing, automated accessibility testing with tools like axe, and manual WCAG 2.1 AA compliance verification."
          },
          {
            "id": 5,
            "title": "Create Advanced Settings Panel for Power Users",
            "description": "Develop a comprehensive settings panel that allows power users to customize their experience and access advanced features.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.4"
            ],
            "details": "Design a modal or sidebar settings panel with categorized options. Implement user preference persistence using localStorage or user profiles. Add advanced options including theme customization, keyboard shortcut configuration, default view preferences, and performance settings (caching levels, prefetch behavior). Include export/import functionality for settings to share configurations between devices or users.",
            "status": "pending",
            "testStrategy": "User testing with power users and administrators, settings persistence testing across sessions, validation of setting effects on application behavior."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-11-14T23:33:40.512Z",
      "updated": "2025-11-14T23:34:10.803Z",
      "description": "UI/UX simplification and improvements to reduce complexity and improve user experience"
    }
  },
  "ui-redesign": {
    "tasks": [],
    "metadata": {
      "created": "2025-11-15T12:56:47.850Z",
      "updated": "2025-11-15T12:56:47.850Z",
      "description": "Complete UI redesign implementing Editorial Newspaper aesthetic with comic elements"
    }
  }
}